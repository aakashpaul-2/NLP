{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Pythorch_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbdpMAw4+N8tnDdM609swU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakashpaul-2/NLP/blob/main/NLP_Pythorch_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ZIY4Aqow-X"
      },
      "source": [
        "''' \n",
        "This project uses LSTM and PYTORCH to create a ham/spam detector\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtmrTTBxHrAa"
      },
      "source": [
        "# imports\n",
        "import torchtext.data as ttd\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from torchtext.vocab import GloVe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEfmVD0WoCkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726bc9e8-b366-4086-c821-86856ed0250e"
      },
      "source": [
        "# import dataset\n",
        "!wget -nc https://lazyprogrammer.me/course_files/spam.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-01 23:19:31--  https://lazyprogrammer.me/course_files/spam.csv\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 104.21.23.210, 172.67.213.166, 2606:4700:3031::6815:17d2, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|104.21.23.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503663 (492K) [text/csv]\n",
            "Saving to: ‘spam.csv’\n",
            "\n",
            "spam.csv            100%[===================>] 491.86K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-03-01 23:19:32 (115 MB/s) - ‘spam.csv’ saved [503663/503663]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbsYYUOqoLAA"
      },
      "source": [
        "# store as dataframe\n",
        "df = pd.read_csv(\"spam.csv\", encoding = \"ISO-8859-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfJLIYoPoWfI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4da67174-13e1-49fc-a90b-03611a5bd8a8"
      },
      "source": [
        "# view df\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ijpdxuIoeww"
      },
      "source": [
        "# drop unused column and rename columns\n",
        "df = df.drop([\"Unnamed: 2\",\"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
        "df.columns = [\"labels\", \"data\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIqCHBZ9o4Nx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9e145f4f-9c5d-4bc3-c64e-a8823a5347ae"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels                                               data\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNVYFR7bpL5c"
      },
      "source": [
        "# mapping lables to catogorical values\n",
        "df[\"b_labels\"] = df[\"labels\"].map({\"ham\":0, \"spam\":1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgsHULOKpd25"
      },
      "source": [
        "df2 = df[[\"data\", \"b_labels\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KPRvSoQpmwY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b61f3c42-8343-40cf-c591-13aa78072f50"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>b_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  b_labels\n",
              "0  Go until jurong point, crazy.. Available only ...         0\n",
              "1                      Ok lar... Joking wif u oni...         0\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...         1\n",
              "3  U dun say so early hor... U c already then say...         0\n",
              "4  Nah I don't think he goes to usf, he lives aro...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se012vcHpn2A"
      },
      "source": [
        "# converting df to csv \n",
        "df2.to_csv(\"spam2.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H93BK9v2pwJo"
      },
      "source": [
        "# Creating filed objects for pytorch model\n",
        "# TEXT - input data (for sequence of data, lower case, N*D*T, pre padding)\n",
        "TEXT = ttd.Field(sequential = True, lower = True, batch_first = True, pad_first = True, tokenize = \"spacy\")\n",
        "\n",
        "# Setting the label as the targets into the LABEL object (numerical labels)\n",
        "LABEL = ttd.Field(sequential = False, use_vocab = False, is_target = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSZS1WNgqN-Z"
      },
      "source": [
        "# assiging the csv (for torch text tabular dataset) and labels to the TEXT and LABEL objects created to tokenise\n",
        "dataset = ttd.TabularDataset(path = \"spam2.csv\", format = \"csv\", skip_header = True, fields = [(\"data\",TEXT),(\"b_labels\",LABEL)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ods6eSFUrnl8"
      },
      "source": [
        "# Splitting dataset into train and test\n",
        "train_dataset, test_dataset = dataset.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNC6nVOcy3aF"
      },
      "source": [
        "# assigns unique interger to each token in dataset\n",
        "TEXT.build_vocab(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RynC9bD3y8rr"
      },
      "source": [
        "# assigning vocab object\n",
        "vocab = TEXT.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60GmxKIGzBjs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6c7607d-91c2-4952-90ac-92069668c6ec"
      },
      "source": [
        "# visualise the unique integer assigned to each token\n",
        "vocab.stoi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'<unk>': 0,\n",
              "             '<pad>': 1,\n",
              "             '.': 2,\n",
              "             'i': 3,\n",
              "             'to': 4,\n",
              "             'you': 5,\n",
              "             ',': 6,\n",
              "             '?': 7,\n",
              "             'a': 8,\n",
              "             'the': 9,\n",
              "             '!': 10,\n",
              "             '...': 11,\n",
              "             'u': 12,\n",
              "             'and': 13,\n",
              "             'is': 14,\n",
              "             'in': 15,\n",
              "             'me': 16,\n",
              "             'my': 17,\n",
              "             'it': 18,\n",
              "             'for': 19,\n",
              "             'your': 20,\n",
              "             '..': 21,\n",
              "             'of': 22,\n",
              "             'do': 23,\n",
              "             'that': 24,\n",
              "             'have': 25,\n",
              "             'call': 26,\n",
              "             '&': 27,\n",
              "             'on': 28,\n",
              "             'now': 29,\n",
              "             'are': 30,\n",
              "             'so': 31,\n",
              "             '2': 32,\n",
              "             ' ': 33,\n",
              "             \"'s\": 34,\n",
              "             'but': 35,\n",
              "             ';': 36,\n",
              "             'not': 37,\n",
              "             'at': 38,\n",
              "             'can': 39,\n",
              "             'be': 40,\n",
              "             'or': 41,\n",
              "             ':': 42,\n",
              "             'get': 43,\n",
              "             'will': 44,\n",
              "             'we': 45,\n",
              "             \"'m\": 46,\n",
              "             'ur': 47,\n",
              "             'if': 48,\n",
              "             'just': 49,\n",
              "             'with': 50,\n",
              "             \"n't\": 51,\n",
              "             'this': 52,\n",
              "             'nt': 53,\n",
              "             'no': 54,\n",
              "             '*': 55,\n",
              "             'when': 56,\n",
              "             'how': 57,\n",
              "             '-': 58,\n",
              "             'go': 59,\n",
              "             'up': 60,\n",
              "             'from': 61,\n",
              "             '4': 62,\n",
              "             'ok': 63,\n",
              "             'lt;#&gt': 64,\n",
              "             'what': 65,\n",
              "             ')': 66,\n",
              "             'all': 67,\n",
              "             'out': 68,\n",
              "             'free': 69,\n",
              "             'know': 70,\n",
              "             'like': 71,\n",
              "             'then': 72,\n",
              "             '\"': 73,\n",
              "             'was': 74,\n",
              "             'got': 75,\n",
              "             '/': 76,\n",
              "             'am': 77,\n",
              "             'there': 78,\n",
              "             'good': 79,\n",
              "             'day': 80,\n",
              "             'come': 81,\n",
              "             'he': 82,\n",
              "             'only': 83,\n",
              "             'its': 84,\n",
              "             'love': 85,\n",
              "             'time': 86,\n",
              "             'as': 87,\n",
              "             'did': 88,\n",
              "             'one': 89,\n",
              "             'send': 90,\n",
              "             \"'ll\": 91,\n",
              "             'want': 92,\n",
              "             'text': 93,\n",
              "             'lor': 94,\n",
              "             'home': 95,\n",
              "             'about': 96,\n",
              "             'by': 97,\n",
              "             'see': 98,\n",
              "             'need': 99,\n",
              "             'n': 100,\n",
              "             'txt': 101,\n",
              "             'back': 102,\n",
              "             'she': 103,\n",
              "             'going': 104,\n",
              "             'sorry': 105,\n",
              "             'today': 106,\n",
              "             'r': 107,\n",
              "             'stop': 108,\n",
              "             'our': 109,\n",
              "             'da': 110,\n",
              "             '_': 111,\n",
              "             'they': 112,\n",
              "             'hi': 113,\n",
              "             'take': 114,\n",
              "             'been': 115,\n",
              "             'new': 116,\n",
              "             'still': 117,\n",
              "             'any': 118,\n",
              "             'mobile': 119,\n",
              "             'reply': 120,\n",
              "             'tell': 121,\n",
              "             'ca': 122,\n",
              "             'her': 123,\n",
              "             'please': 124,\n",
              "             'week': 125,\n",
              "             'well': 126,\n",
              "             'has': 127,\n",
              "             'later': 128,\n",
              "             \"'\": 129,\n",
              "             'phone': 130,\n",
              "             'think': 131,\n",
              "             'hope': 132,\n",
              "             'pls': 133,\n",
              "             'happy': 134,\n",
              "             'who': 135,\n",
              "             'some': 136,\n",
              "             'd': 137,\n",
              "             'night': 138,\n",
              "             'ì': 139,\n",
              "             'an': 140,\n",
              "             'here': 141,\n",
              "             'make': 142,\n",
              "             'where': 143,\n",
              "             'had': 144,\n",
              "             'great': 145,\n",
              "             'should': 146,\n",
              "             'too': 147,\n",
              "             'dear': 148,\n",
              "             'much': 149,\n",
              "             'oh': 150,\n",
              "             'him': 151,\n",
              "             'more': 152,\n",
              "             'way': 153,\n",
              "             'hey': 154,\n",
              "             'number': 155,\n",
              "             's': 156,\n",
              "             'already': 157,\n",
              "             'really': 158,\n",
              "             \"'ve\": 159,\n",
              "             'wat': 160,\n",
              "             'give': 161,\n",
              "             'msg': 162,\n",
              "             'claim': 163,\n",
              "             'k': 164,\n",
              "             'e': 165,\n",
              "             'say': 166,\n",
              "             'them': 167,\n",
              "             'yes': 168,\n",
              "             'said': 169,\n",
              "             'message': 170,\n",
              "             'ask': 171,\n",
              "             'work': 172,\n",
              "             'morning': 173,\n",
              "             'would': 174,\n",
              "             'amp': 175,\n",
              "             'doing': 176,\n",
              "             'c': 177,\n",
              "             'tomorrow': 178,\n",
              "             'after': 179,\n",
              "             'yeah': 180,\n",
              "             '1': 181,\n",
              "             'cash': 182,\n",
              "             'every': 183,\n",
              "             'keep': 184,\n",
              "             'meet': 185,\n",
              "             \"'re\": 186,\n",
              "             'let': 187,\n",
              "             'right': 188,\n",
              "             'find': 189,\n",
              "             'why': 190,\n",
              "             '+': 191,\n",
              "             'also': 192,\n",
              "             'care': 193,\n",
              "             'prize': 194,\n",
              "             '(': 195,\n",
              "             'cos': 196,\n",
              "             'nokia': 197,\n",
              "             'something': 198,\n",
              "             '3': 199,\n",
              "             'babe': 200,\n",
              "             'life': 201,\n",
              "             'were': 202,\n",
              "             'miss': 203,\n",
              "             'anything': 204,\n",
              "             'buy': 205,\n",
              "             'feel': 206,\n",
              "             'm': 207,\n",
              "             'pick': 208,\n",
              "             'very': 209,\n",
              "             'last': 210,\n",
              "             'min': 211,\n",
              "             'went': 212,\n",
              "             'b': 213,\n",
              "             'over': 214,\n",
              "             'sent': 215,\n",
              "             'sure': 216,\n",
              "             'which': 217,\n",
              "             'could': 218,\n",
              "             'lol': 219,\n",
              "             'place': 220,\n",
              "             'thanks': 221,\n",
              "             'us': 222,\n",
              "             'again': 223,\n",
              "             'even': 224,\n",
              "             'friends': 225,\n",
              "             'win': 226,\n",
              "             'na': 227,\n",
              "             'service': 228,\n",
              "             'someone': 229,\n",
              "             '150p': 230,\n",
              "             ':)': 231,\n",
              "             'before': 232,\n",
              "             'wait': 233,\n",
              "             'contact': 234,\n",
              "             'thing': 235,\n",
              "             'won': 236,\n",
              "             'always': 237,\n",
              "             'first': 238,\n",
              "             'late': 239,\n",
              "             'nice': 240,\n",
              "             'per': 241,\n",
              "             'smile': 242,\n",
              "             'tone': 243,\n",
              "             'ya': 244,\n",
              "             'around': 245,\n",
              "             'chat': 246,\n",
              "             'does': 247,\n",
              "             'many': 248,\n",
              "             'sleep': 249,\n",
              "             'things': 250,\n",
              "             'wo': 251,\n",
              "             'customer': 252,\n",
              "             'dun': 253,\n",
              "             'gud': 254,\n",
              "             'next': 255,\n",
              "             'off': 256,\n",
              "             'other': 257,\n",
              "             'special': 258,\n",
              "             'ìï': 259,\n",
              "             '....': 260,\n",
              "             'gon': 261,\n",
              "             'help': 262,\n",
              "             'may': 263,\n",
              "             'soon': 264,\n",
              "             'told': 265,\n",
              "             'wan': 266,\n",
              "             'wish': 267,\n",
              "             'down': 268,\n",
              "             'his': 269,\n",
              "             'thought': 270,\n",
              "             'tonight': 271,\n",
              "             'waiting': 272,\n",
              "             'coming': 273,\n",
              "             'heart': 274,\n",
              "             'leave': 275,\n",
              "             'never': 276,\n",
              "             'done': 277,\n",
              "             'money': 278,\n",
              "             'urgent': 279,\n",
              "             'use': 280,\n",
              "             'v': 281,\n",
              "             '16': 282,\n",
              "             'better': 283,\n",
              "             'class': 284,\n",
              "             'haha': 285,\n",
              "             'live': 286,\n",
              "             'man': 287,\n",
              "             'thk': 288,\n",
              "             'end': 289,\n",
              "             'friend': 290,\n",
              "             'house': 291,\n",
              "             'people': 292,\n",
              "             'x': 293,\n",
              "             'year': 294,\n",
              "             'few': 295,\n",
              "             'guess': 296,\n",
              "             'having': 297,\n",
              "             'lunch': 298,\n",
              "             'mind': 299,\n",
              "             'same': 300,\n",
              "             '18': 301,\n",
              "             '5': 302,\n",
              "             'holiday': 303,\n",
              "             'job': 304,\n",
              "             'name': 305,\n",
              "             'sms': 306,\n",
              "             'wanna': 307,\n",
              "             'yup': 308,\n",
              "             'best': 309,\n",
              "             'bit': 310,\n",
              "             'days': 311,\n",
              "             'fine': 312,\n",
              "             'getting': 313,\n",
              "             'hello': 314,\n",
              "             'lar': 315,\n",
              "             'long': 316,\n",
              "             'mins': 317,\n",
              "             'nothing': 318,\n",
              "             'stuff': 319,\n",
              "             'talk': 320,\n",
              "             'than': 321,\n",
              "             'u.': 322,\n",
              "             'y': 323,\n",
              "             'guaranteed': 324,\n",
              "             'ready': 325,\n",
              "             'yet': 326,\n",
              "             '1st': 327,\n",
              "             'chance': 328,\n",
              "             'early': 329,\n",
              "             'into': 330,\n",
              "             'line': 331,\n",
              "             'meeting': 332,\n",
              "             'person': 333,\n",
              "             'play': 334,\n",
              "             'check': 335,\n",
              "             'draw': 336,\n",
              "             'dunno': 337,\n",
              "             'finish': 338,\n",
              "             'guys': 339,\n",
              "             'half': 340,\n",
              "             'ill': 341,\n",
              "             'lot': 342,\n",
              "             'sir': 343,\n",
              "             'try': 344,\n",
              "             'word': 345,\n",
              "             'yo': 346,\n",
              "             'account': 347,\n",
              "             'birthday': 348,\n",
              "             'car': 349,\n",
              "             'dat': 350,\n",
              "             'den': 351,\n",
              "             'dinner': 352,\n",
              "             'god': 353,\n",
              "             'latest': 354,\n",
              "             'luv': 355,\n",
              "             'receive': 356,\n",
              "             'trying': 357,\n",
              "             'world': 358,\n",
              "             '150ppm': 359,\n",
              "             'another': 360,\n",
              "             'bad': 361,\n",
              "             'bed': 362,\n",
              "             'being': 363,\n",
              "             'big': 364,\n",
              "             'cool': 365,\n",
              "             'liao': 366,\n",
              "             'offer': 367,\n",
              "             'once': 368,\n",
              "             'real': 369,\n",
              "             'shall': 370,\n",
              "             'start': 371,\n",
              "             'two': 372,\n",
              "             'box': 373,\n",
              "             'camera': 374,\n",
              "             'eat': 375,\n",
              "             'enjoy': 376,\n",
              "             'fuck': 377,\n",
              "             'girl': 378,\n",
              "             'i.ll': 379,\n",
              "             'landline': 380,\n",
              "             'month': 381,\n",
              "             'problem': 382,\n",
              "             'reach': 383,\n",
              "             'room': 384,\n",
              "             'sweet': 385,\n",
              "             'thanx': 386,\n",
              "             'watching': 387,\n",
              "             'wk': 388,\n",
              "             'actually': 389,\n",
              "             'awarded': 390,\n",
              "             'baby': 391,\n",
              "             'bring': 392,\n",
              "             'cost': 393,\n",
              "             'forgot': 394,\n",
              "             'hear': 395,\n",
              "             'important': 396,\n",
              "             'jus': 397,\n",
              "             'kiss': 398,\n",
              "             'look': 399,\n",
              "             'minutes': 400,\n",
              "             'okay': 401,\n",
              "             'pay': 402,\n",
              "             'quite': 403,\n",
              "             'remember': 404,\n",
              "             'speak': 405,\n",
              "             'till': 406,\n",
              "             'video': 407,\n",
              "             'wanted': 408,\n",
              "             '9': 409,\n",
              "             'asked': 410,\n",
              "             'between': 411,\n",
              "             'bt': 412,\n",
              "             'called': 413,\n",
              "             'fun': 414,\n",
              "             'g': 415,\n",
              "             'lei': 416,\n",
              "             'looking': 417,\n",
              "             'might': 418,\n",
              "             'orange': 419,\n",
              "             'school': 420,\n",
              "             'shopping': 421,\n",
              "             'those': 422,\n",
              "             'though': 423,\n",
              "             '>': 424,\n",
              "             'afternoon': 425,\n",
              "             'ah': 426,\n",
              "             'aight': 427,\n",
              "             'because': 428,\n",
              "             'came': 429,\n",
              "             'code': 430,\n",
              "             'easy': 431,\n",
              "             'entry': 432,\n",
              "             'hour': 433,\n",
              "             'little': 434,\n",
              "             'maybe': 435,\n",
              "             'part': 436,\n",
              "             'plan': 437,\n",
              "             'pm': 438,\n",
              "             'show': 439,\n",
              "             'shows': 440,\n",
              "             'til': 441,\n",
              "             'wif': 442,\n",
              "             'without': 443,\n",
              "             '6': 444,\n",
              "             'anyway': 445,\n",
              "             'hav': 446,\n",
              "             'made': 447,\n",
              "             'makes': 448,\n",
              "             'must': 449,\n",
              "             'po': 450,\n",
              "             'put': 451,\n",
              "             'sat': 452,\n",
              "             'selected': 453,\n",
              "             'shit': 454,\n",
              "             't': 455,\n",
              "             'times': 456,\n",
              "             'true': 457,\n",
              "             'tv': 458,\n",
              "             'until': 459,\n",
              "             'while': 460,\n",
              "             'working': 461,\n",
              "             'boy': 462,\n",
              "             'collect': 463,\n",
              "             'coz': 464,\n",
              "             'dad': 465,\n",
              "             'details': 466,\n",
              "             'enough': 467,\n",
              "             'gift': 468,\n",
              "             'goes': 469,\n",
              "             'hair': 470,\n",
              "             'leh': 471,\n",
              "             'most': 472,\n",
              "             'music': 473,\n",
              "             'office': 474,\n",
              "             'pain': 475,\n",
              "             'plus': 476,\n",
              "             're': 477,\n",
              "             'says': 478,\n",
              "             'texts': 479,\n",
              "             'watch': 480,\n",
              "             'weekend': 481,\n",
              "             'wife': 482,\n",
              "             'years': 483,\n",
              "             'yours': 484,\n",
              "             'å£1000': 485,\n",
              "             '2nd': 486,\n",
              "             'alright': 487,\n",
              "             'apply': 488,\n",
              "             'bus': 489,\n",
              "             'calls': 490,\n",
              "             'dis': 491,\n",
              "             'dude': 492,\n",
              "             'else': 493,\n",
              "             'evening': 494,\n",
              "             'everything': 495,\n",
              "             'food': 496,\n",
              "             'lt;decimal&gt': 497,\n",
              "             'means': 498,\n",
              "             'network': 499,\n",
              "             'old': 500,\n",
              "             'pa': 501,\n",
              "             'post': 502,\n",
              "             'probably': 503,\n",
              "             'rate': 504,\n",
              "             'ringtone': 505,\n",
              "             'run': 506,\n",
              "             'shop': 507,\n",
              "             'tones': 508,\n",
              "             'town': 509,\n",
              "             'wake': 510,\n",
              "             'wid': 511,\n",
              "             'å£100': 512,\n",
              "             '10p': 513,\n",
              "             '7': 514,\n",
              "             'able': 515,\n",
              "             'book': 516,\n",
              "             'collection': 517,\n",
              "             'double': 518,\n",
              "             'ever': 519,\n",
              "             'feeling': 520,\n",
              "             'huh': 521,\n",
              "             'hurt': 522,\n",
              "             'left': 523,\n",
              "             'messages': 524,\n",
              "             'missing': 525,\n",
              "             'plz': 526,\n",
              "             'price': 527,\n",
              "             'princess': 528,\n",
              "             'sad': 529,\n",
              "             'sexy': 530,\n",
              "             't&cs': 531,\n",
              "             'test': 532,\n",
              "             'these': 533,\n",
              "             'tmr': 534,\n",
              "             'vouchers': 535,\n",
              "             'worry': 536,\n",
              "             'wot': 537,\n",
              "             'xmas': 538,\n",
              "             'yourself': 539,\n",
              "             \"'d\": 540,\n",
              "             '=': 541,\n",
              "             '\\\\': 542,\n",
              "             'abt': 543,\n",
              "             'beautiful': 544,\n",
              "             'de': 545,\n",
              "             'driving': 546,\n",
              "             'either': 547,\n",
              "             'haf': 548,\n",
              "             'hot': 549,\n",
              "             'juz': 550,\n",
              "             'movie': 551,\n",
              "             'noe': 552,\n",
              "             'online': 553,\n",
              "             'oso': 554,\n",
              "             'rite': 555,\n",
              "             'sch': 556,\n",
              "             'since': 557,\n",
              "             'took': 558,\n",
              "             'update': 559,\n",
              "             'valid': 560,\n",
              "             'weekly': 561,\n",
              "             '10': 562,\n",
              "             '500': 563,\n",
              "             'award': 564,\n",
              "             'away': 565,\n",
              "             'bored': 566,\n",
              "             'change': 567,\n",
              "             'close': 568,\n",
              "             'comes': 569,\n",
              "             'dreams': 570,\n",
              "             'drop': 571,\n",
              "             'forget': 572,\n",
              "             'full': 573,\n",
              "             'goin': 574,\n",
              "             'gr8': 575,\n",
              "             'head': 576,\n",
              "             'hours': 577,\n",
              "             'join': 578,\n",
              "             'making': 579,\n",
              "             'missed': 580,\n",
              "             'needs': 581,\n",
              "             'open': 582,\n",
              "             'order': 583,\n",
              "             'ring': 584,\n",
              "             'sae': 585,\n",
              "             'saying': 586,\n",
              "             'sleeping': 587,\n",
              "             'started': 588,\n",
              "             'sun': 589,\n",
              "             'taking': 590,\n",
              "             'together': 591,\n",
              "             'tomo': 592,\n",
              "             'type': 593,\n",
              "             'walk': 594,\n",
              "             'xxx': 595,\n",
              "             'å£5000': 596,\n",
              "             '$': 597,\n",
              "             '8': 598,\n",
              "             'answer': 599,\n",
              "             'await': 600,\n",
              "             'both': 601,\n",
              "             'calling': 602,\n",
              "             'club': 603,\n",
              "             'dating': 604,\n",
              "             'delivery': 605,\n",
              "             'eve': 606,\n",
              "             'face': 607,\n",
              "             'family': 608,\n",
              "             'final': 609,\n",
              "             'game': 610,\n",
              "             'gone': 611,\n",
              "             'guy': 612,\n",
              "             'happen': 613,\n",
              "             'hard': 614,\n",
              "             'leaving': 615,\n",
              "             'mail': 616,\n",
              "             'mom': 617,\n",
              "             'national': 618,\n",
              "             'okie': 619,\n",
              "             'parents': 620,\n",
              "             'row': 621,\n",
              "             'saw': 622,\n",
              "             'services': 623,\n",
              "             'smiling': 624,\n",
              "             'snow': 625,\n",
              "             'stay': 626,\n",
              "             'story': 627,\n",
              "             'ta': 628,\n",
              "             'thank': 629,\n",
              "             'top': 630,\n",
              "             'tried': 631,\n",
              "             'trip': 632,\n",
              "             'uk': 633,\n",
              "             'wen': 634,\n",
              "             'words': 635,\n",
              "             '8007': 636,\n",
              "             ':-(': 637,\n",
              "             'ard': 638,\n",
              "             'attempt': 639,\n",
              "             'believe': 640,\n",
              "             'blue': 641,\n",
              "             'boytoy': 642,\n",
              "             'charge': 643,\n",
              "             'colour': 644,\n",
              "             'congrats': 645,\n",
              "             'father': 646,\n",
              "             'found': 647,\n",
              "             'frm': 648,\n",
              "             'happened': 649,\n",
              "             'kind': 650,\n",
              "             'listen': 651,\n",
              "             'mates': 652,\n",
              "             'mine': 653,\n",
              "             'minute': 654,\n",
              "             'mob': 655,\n",
              "             'neva': 656,\n",
              "             'nite': 657,\n",
              "             'opt': 658,\n",
              "             'oredi': 659,\n",
              "             'pobox': 660,\n",
              "             'points': 661,\n",
              "             'poly': 662,\n",
              "             'pub': 663,\n",
              "             'search': 664,\n",
              "             'second': 665,\n",
              "             'seeing': 666,\n",
              "             'set': 667,\n",
              "             'smoke': 668,\n",
              "             't&c': 669,\n",
              "             'takes': 670,\n",
              "             'tel': 671,\n",
              "             'tho': 672,\n",
              "             'touch': 673,\n",
              "             'worth': 674,\n",
              "             'www': 675,\n",
              "             '||': 676,\n",
              "             'å£1.50': 677,\n",
              "             'å£2000': 678,\n",
              "             \"''\": 679,\n",
              "             '750': 680,\n",
              "             '86688': 681,\n",
              "             ':-)': 682,\n",
              "             'address': 683,\n",
              "             'angry': 684,\n",
              "             'anyone': 685,\n",
              "             'auction': 686,\n",
              "             'awesome': 687,\n",
              "             'busy': 688,\n",
              "             'carlos': 689,\n",
              "             'choose': 690,\n",
              "             'date': 691,\n",
              "             'drink': 692,\n",
              "             'email': 693,\n",
              "             'fr': 694,\n",
              "             'games': 695,\n",
              "             'gd': 696,\n",
              "             'girls': 697,\n",
              "             'hee': 698,\n",
              "             'hungry': 699,\n",
              "             'john': 700,\n",
              "             'lose': 701,\n",
              "             'pics': 702,\n",
              "             'project': 703,\n",
              "             'question': 704,\n",
              "             'reason': 705,\n",
              "             'savamob': 706,\n",
              "             'sis': 707,\n",
              "             'ten': 708,\n",
              "             'thinking': 709,\n",
              "             'thinks': 710,\n",
              "             'todays': 711,\n",
              "             'tot': 712,\n",
              "             'unsubscribe': 713,\n",
              "             'used': 714,\n",
              "             'voucher': 715,\n",
              "             'wants': 716,\n",
              "             'whatever': 717,\n",
              "             'whole': 718,\n",
              "             'å£500': 719,\n",
              "             '12hrs': 720,\n",
              "             'aft': 721,\n",
              "             'bank': 722,\n",
              "             'break': 723,\n",
              "             'brother': 724,\n",
              "             'cause': 725,\n",
              "             'company': 726,\n",
              "             'confirm': 727,\n",
              "             'congratulations': 728,\n",
              "             'content': 729,\n",
              "             'decided': 730,\n",
              "             'die': 731,\n",
              "             'enter': 732,\n",
              "             'everyone': 733,\n",
              "             'exam': 734,\n",
              "             'expires': 735,\n",
              "             'far': 736,\n",
              "             'fast': 737,\n",
              "             'felt': 738,\n",
              "             'finished': 739,\n",
              "             'happiness': 740,\n",
              "             'invited': 741,\n",
              "             'land': 742,\n",
              "             'lesson': 743,\n",
              "             'lets': 744,\n",
              "             'lots': 745,\n",
              "             'lucky': 746,\n",
              "             'mayb': 747,\n",
              "             'mean': 748,\n",
              "             'mobileupd8': 749,\n",
              "             'mum': 750,\n",
              "             'news': 751,\n",
              "             'offers': 752,\n",
              "             'pounds': 753,\n",
              "             'private': 754,\n",
              "             'saturday': 755,\n",
              "             'secret': 756,\n",
              "             'sounds': 757,\n",
              "             'understand': 758,\n",
              "             'yesterday': 759,\n",
              "             'å£250': 760,\n",
              "             '87066': 761,\n",
              "             'age': 762,\n",
              "             'ans': 763,\n",
              "             'anytime': 764,\n",
              "             'ass': 765,\n",
              "             'available': 766,\n",
              "             'bathe': 767,\n",
              "             'bonus': 768,\n",
              "             'chikku': 769,\n",
              "             'crazy': 770,\n",
              "             'difficult': 771,\n",
              "             'discount': 772,\n",
              "             'download': 773,\n",
              "             'drive': 774,\n",
              "             'each': 775,\n",
              "             'empty': 776,\n",
              "             'etc': 777,\n",
              "             'freemsg': 778,\n",
              "             'friday': 779,\n",
              "             'friendship': 780,\n",
              "             'gets': 781,\n",
              "             'hand': 782,\n",
              "             'hmm': 783,\n",
              "             'identifier': 784,\n",
              "             'im': 785,\n",
              "             'joy': 786,\n",
              "             'log': 787,\n",
              "             'lovely': 788,\n",
              "             'loving': 789,\n",
              "             'ltd': 790,\n",
              "             'luck': 791,\n",
              "             'march': 792,\n",
              "             'motorola': 793,\n",
              "             'mrng': 794,\n",
              "             'nope': 795,\n",
              "             'operator': 796,\n",
              "             'outside': 797,\n",
              "             'party': 798,\n",
              "             'phones': 799,\n",
              "             'plans': 800,\n",
              "             'remove': 801,\n",
              "             'rs': 802,\n",
              "             'sending': 803,\n",
              "             'shower': 804,\n",
              "             'sister': 805,\n",
              "             'statement': 806,\n",
              "             'suite342/2lands': 807,\n",
              "             'supposed': 808,\n",
              "             'talking': 809,\n",
              "             'their': 810,\n",
              "             'un': 811,\n",
              "             'visit': 812,\n",
              "             'weeks': 813,\n",
              "             'welcome': 814,\n",
              "             'wil': 815,\n",
              "             'wit': 816,\n",
              "             'wonderful': 817,\n",
              "             'wow': 818,\n",
              "             '\\x89û': 819,\n",
              "             '.....': 820,\n",
              "             '08000839402': 821,\n",
              "             '2003': 822,\n",
              "             '800': 823,\n",
              "             '@': 824,\n",
              "             'admirer': 825,\n",
              "             'almost': 826,\n",
              "             'alone': 827,\n",
              "             'balance': 828,\n",
              "             'bslvyl': 829,\n",
              "             'card': 830,\n",
              "             'chennai': 831,\n",
              "             'christmas': 832,\n",
              "             'college': 833,\n",
              "             'complimentary': 834,\n",
              "             'couple': 835,\n",
              "             'crave': 836,\n",
              "             'credit': 837,\n",
              "             'cut': 838,\n",
              "             'darlin': 839,\n",
              "             'earlier': 840,\n",
              "             'eg': 841,\n",
              "             'ends': 842,\n",
              "             'england': 843,\n",
              "             'ex': 844,\n",
              "             'extra': 845,\n",
              "             'fancy': 846,\n",
              "             'fri': 847,\n",
              "             'gas': 848,\n",
              "             'grins': 849,\n",
              "             'hit': 850,\n",
              "             'ho': 851,\n",
              "             'information': 852,\n",
              "             'kids': 853,\n",
              "             'knew': 854,\n",
              "             'lost': 855,\n",
              "             'mate': 856,\n",
              "             'mobiles': 857,\n",
              "             'monday': 858,\n",
              "             'msgs': 859,\n",
              "             'ntt': 860,\n",
              "             'numbers': 861,\n",
              "             'oops': 862,\n",
              "             'orchard': 863,\n",
              "             'picking': 864,\n",
              "             'player': 865,\n",
              "             'pretty': 866,\n",
              "             'prob': 867,\n",
              "             'reached': 868,\n",
              "             'redeemed': 869,\n",
              "             'reward': 870,\n",
              "             'save': 871,\n",
              "             'sea': 872,\n",
              "             'sex': 873,\n",
              "             'side': 874,\n",
              "             'slow': 875,\n",
              "             'small': 876,\n",
              "             'sort': 877,\n",
              "             'support': 878,\n",
              "             'tc': 879,\n",
              "             'through': 880,\n",
              "             'tickets': 881,\n",
              "             'trust': 882,\n",
              "             'txts': 883,\n",
              "             'uncle': 884,\n",
              "             'unlimited': 885,\n",
              "             'valentine': 886,\n",
              "             'w': 887,\n",
              "             'wana': 888,\n",
              "             'whenever': 889,\n",
              "             'within': 890,\n",
              "             'wkly': 891,\n",
              "             'wonder': 892,\n",
              "             '\\x89ûò': 893,\n",
              "             'å£350': 894,\n",
              "             '08000930705': 895,\n",
              "             '100': 896,\n",
              "             '20p': 897,\n",
              "             'al': 898,\n",
              "             'area': 899,\n",
              "             'askd': 900,\n",
              "             'asking': 901,\n",
              "             \"b'day\": 902,\n",
              "             'b4': 903,\n",
              "             'bb': 904,\n",
              "             'bill': 905,\n",
              "             'bout': 906,\n",
              "             'brings': 907,\n",
              "             'callertune': 908,\n",
              "             'case': 909,\n",
              "             'charged': 910,\n",
              "             'cheap': 911,\n",
              "             'comp': 912,\n",
              "             'copy': 913,\n",
              "             'correct': 914,\n",
              "             'course': 915,\n",
              "             'cs': 916,\n",
              "             'dogging': 917,\n",
              "             'don': 918,\n",
              "             'dream': 919,\n",
              "             'eh': 920,\n",
              "             'f': 921,\n",
              "             'fact': 922,\n",
              "             'finally': 923,\n",
              "             'freephone': 924,\n",
              "             'frnds': 925,\n",
              "             'gave': 926,\n",
              "             'gettin': 927,\n",
              "             'gt': 928,\n",
              "             'gym': 929,\n",
              "             'heard': 930,\n",
              "             'india': 931,\n",
              "             'info': 932,\n",
              "             'k.': 933,\n",
              "             'kate': 934,\n",
              "             'laptop': 935,\n",
              "             'less': 936,\n",
              "             'lessons': 937,\n",
              "             'light': 938,\n",
              "             'loads': 939,\n",
              "             'loved': 940,\n",
              "             'match': 941,\n",
              "             'meant': 942,\n",
              "             'moment': 943,\n",
              "             'months': 944,\n",
              "             'move': 945,\n",
              "             'mu': 946,\n",
              "             'muz': 947,\n",
              "             'nah': 948,\n",
              "             'net': 949,\n",
              "             'ni8': 950,\n",
              "             'nyt': 951,\n",
              "             'paper': 952,\n",
              "             'pic': 953,\n",
              "             'point': 954,\n",
              "             'police': 955,\n",
              "             'quiz': 956,\n",
              "             'reaching': 957,\n",
              "             'reading': 958,\n",
              "             'rock': 959,\n",
              "             'rply': 960,\n",
              "             's.': 961,\n",
              "             'slowly': 962,\n",
              "             'smth': 963,\n",
              "             'st': 964,\n",
              "             'staying': 965,\n",
              "             'summer': 966,\n",
              "             'telling': 967,\n",
              "             'th': 968,\n",
              "             'tonite': 969,\n",
              "             'treat': 970,\n",
              "             'ts&cs': 971,\n",
              "             'ugh': 972,\n",
              "             'unless': 973,\n",
              "             'warm': 974,\n",
              "             'wine': 975,\n",
              "             'winner': 976,\n",
              "             'wishing': 977,\n",
              "             'woke': 978,\n",
              "             'wondering': 979,\n",
              "             'worries': 980,\n",
              "             'wrong': 981,\n",
              "             'xx': 982,\n",
              "             'yr': 983,\n",
              "             '#': 984,\n",
              "             '0800': 985,\n",
              "             '0870': 986,\n",
              "             '11': 987,\n",
              "             '2day': 988,\n",
              "             'abiola': 989,\n",
              "             'accept': 990,\n",
              "             'ar': 991,\n",
              "             'bcoz': 992,\n",
              "             'booked': 993,\n",
              "             'boss': 994,\n",
              "             'buzz': 995,\n",
              "             'camcorder': 996,\n",
              "             'catch': 997,\n",
              "             'cd': 998,\n",
              "             'checking': 999,\n",
              "             ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAuVUi0dzDIs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d7db88f-2ce2-45ae-9ca1-ab4b96a190c2"
      },
      "source": [
        "# list of unique tokens\n",
        "vocab.itos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '.',\n",
              " 'i',\n",
              " 'to',\n",
              " 'you',\n",
              " ',',\n",
              " '?',\n",
              " 'a',\n",
              " 'the',\n",
              " '!',\n",
              " '...',\n",
              " 'u',\n",
              " 'and',\n",
              " 'is',\n",
              " 'in',\n",
              " 'me',\n",
              " 'my',\n",
              " 'it',\n",
              " 'for',\n",
              " 'your',\n",
              " '..',\n",
              " 'of',\n",
              " 'do',\n",
              " 'that',\n",
              " 'have',\n",
              " 'call',\n",
              " '&',\n",
              " 'on',\n",
              " 'now',\n",
              " 'are',\n",
              " 'so',\n",
              " '2',\n",
              " ' ',\n",
              " \"'s\",\n",
              " 'but',\n",
              " ';',\n",
              " 'not',\n",
              " 'at',\n",
              " 'can',\n",
              " 'be',\n",
              " 'or',\n",
              " ':',\n",
              " 'get',\n",
              " 'will',\n",
              " 'we',\n",
              " \"'m\",\n",
              " 'ur',\n",
              " 'if',\n",
              " 'just',\n",
              " 'with',\n",
              " \"n't\",\n",
              " 'this',\n",
              " 'nt',\n",
              " 'no',\n",
              " '*',\n",
              " 'when',\n",
              " 'how',\n",
              " '-',\n",
              " 'go',\n",
              " 'up',\n",
              " 'from',\n",
              " '4',\n",
              " 'ok',\n",
              " 'lt;#&gt',\n",
              " 'what',\n",
              " ')',\n",
              " 'all',\n",
              " 'out',\n",
              " 'free',\n",
              " 'know',\n",
              " 'like',\n",
              " 'then',\n",
              " '\"',\n",
              " 'was',\n",
              " 'got',\n",
              " '/',\n",
              " 'am',\n",
              " 'there',\n",
              " 'good',\n",
              " 'day',\n",
              " 'come',\n",
              " 'he',\n",
              " 'only',\n",
              " 'its',\n",
              " 'love',\n",
              " 'time',\n",
              " 'as',\n",
              " 'did',\n",
              " 'one',\n",
              " 'send',\n",
              " \"'ll\",\n",
              " 'want',\n",
              " 'text',\n",
              " 'lor',\n",
              " 'home',\n",
              " 'about',\n",
              " 'by',\n",
              " 'see',\n",
              " 'need',\n",
              " 'n',\n",
              " 'txt',\n",
              " 'back',\n",
              " 'she',\n",
              " 'going',\n",
              " 'sorry',\n",
              " 'today',\n",
              " 'r',\n",
              " 'stop',\n",
              " 'our',\n",
              " 'da',\n",
              " '_',\n",
              " 'they',\n",
              " 'hi',\n",
              " 'take',\n",
              " 'been',\n",
              " 'new',\n",
              " 'still',\n",
              " 'any',\n",
              " 'mobile',\n",
              " 'reply',\n",
              " 'tell',\n",
              " 'ca',\n",
              " 'her',\n",
              " 'please',\n",
              " 'week',\n",
              " 'well',\n",
              " 'has',\n",
              " 'later',\n",
              " \"'\",\n",
              " 'phone',\n",
              " 'think',\n",
              " 'hope',\n",
              " 'pls',\n",
              " 'happy',\n",
              " 'who',\n",
              " 'some',\n",
              " 'd',\n",
              " 'night',\n",
              " 'ì',\n",
              " 'an',\n",
              " 'here',\n",
              " 'make',\n",
              " 'where',\n",
              " 'had',\n",
              " 'great',\n",
              " 'should',\n",
              " 'too',\n",
              " 'dear',\n",
              " 'much',\n",
              " 'oh',\n",
              " 'him',\n",
              " 'more',\n",
              " 'way',\n",
              " 'hey',\n",
              " 'number',\n",
              " 's',\n",
              " 'already',\n",
              " 'really',\n",
              " \"'ve\",\n",
              " 'wat',\n",
              " 'give',\n",
              " 'msg',\n",
              " 'claim',\n",
              " 'k',\n",
              " 'e',\n",
              " 'say',\n",
              " 'them',\n",
              " 'yes',\n",
              " 'said',\n",
              " 'message',\n",
              " 'ask',\n",
              " 'work',\n",
              " 'morning',\n",
              " 'would',\n",
              " 'amp',\n",
              " 'doing',\n",
              " 'c',\n",
              " 'tomorrow',\n",
              " 'after',\n",
              " 'yeah',\n",
              " '1',\n",
              " 'cash',\n",
              " 'every',\n",
              " 'keep',\n",
              " 'meet',\n",
              " \"'re\",\n",
              " 'let',\n",
              " 'right',\n",
              " 'find',\n",
              " 'why',\n",
              " '+',\n",
              " 'also',\n",
              " 'care',\n",
              " 'prize',\n",
              " '(',\n",
              " 'cos',\n",
              " 'nokia',\n",
              " 'something',\n",
              " '3',\n",
              " 'babe',\n",
              " 'life',\n",
              " 'were',\n",
              " 'miss',\n",
              " 'anything',\n",
              " 'buy',\n",
              " 'feel',\n",
              " 'm',\n",
              " 'pick',\n",
              " 'very',\n",
              " 'last',\n",
              " 'min',\n",
              " 'went',\n",
              " 'b',\n",
              " 'over',\n",
              " 'sent',\n",
              " 'sure',\n",
              " 'which',\n",
              " 'could',\n",
              " 'lol',\n",
              " 'place',\n",
              " 'thanks',\n",
              " 'us',\n",
              " 'again',\n",
              " 'even',\n",
              " 'friends',\n",
              " 'win',\n",
              " 'na',\n",
              " 'service',\n",
              " 'someone',\n",
              " '150p',\n",
              " ':)',\n",
              " 'before',\n",
              " 'wait',\n",
              " 'contact',\n",
              " 'thing',\n",
              " 'won',\n",
              " 'always',\n",
              " 'first',\n",
              " 'late',\n",
              " 'nice',\n",
              " 'per',\n",
              " 'smile',\n",
              " 'tone',\n",
              " 'ya',\n",
              " 'around',\n",
              " 'chat',\n",
              " 'does',\n",
              " 'many',\n",
              " 'sleep',\n",
              " 'things',\n",
              " 'wo',\n",
              " 'customer',\n",
              " 'dun',\n",
              " 'gud',\n",
              " 'next',\n",
              " 'off',\n",
              " 'other',\n",
              " 'special',\n",
              " 'ìï',\n",
              " '....',\n",
              " 'gon',\n",
              " 'help',\n",
              " 'may',\n",
              " 'soon',\n",
              " 'told',\n",
              " 'wan',\n",
              " 'wish',\n",
              " 'down',\n",
              " 'his',\n",
              " 'thought',\n",
              " 'tonight',\n",
              " 'waiting',\n",
              " 'coming',\n",
              " 'heart',\n",
              " 'leave',\n",
              " 'never',\n",
              " 'done',\n",
              " 'money',\n",
              " 'urgent',\n",
              " 'use',\n",
              " 'v',\n",
              " '16',\n",
              " 'better',\n",
              " 'class',\n",
              " 'haha',\n",
              " 'live',\n",
              " 'man',\n",
              " 'thk',\n",
              " 'end',\n",
              " 'friend',\n",
              " 'house',\n",
              " 'people',\n",
              " 'x',\n",
              " 'year',\n",
              " 'few',\n",
              " 'guess',\n",
              " 'having',\n",
              " 'lunch',\n",
              " 'mind',\n",
              " 'same',\n",
              " '18',\n",
              " '5',\n",
              " 'holiday',\n",
              " 'job',\n",
              " 'name',\n",
              " 'sms',\n",
              " 'wanna',\n",
              " 'yup',\n",
              " 'best',\n",
              " 'bit',\n",
              " 'days',\n",
              " 'fine',\n",
              " 'getting',\n",
              " 'hello',\n",
              " 'lar',\n",
              " 'long',\n",
              " 'mins',\n",
              " 'nothing',\n",
              " 'stuff',\n",
              " 'talk',\n",
              " 'than',\n",
              " 'u.',\n",
              " 'y',\n",
              " 'guaranteed',\n",
              " 'ready',\n",
              " 'yet',\n",
              " '1st',\n",
              " 'chance',\n",
              " 'early',\n",
              " 'into',\n",
              " 'line',\n",
              " 'meeting',\n",
              " 'person',\n",
              " 'play',\n",
              " 'check',\n",
              " 'draw',\n",
              " 'dunno',\n",
              " 'finish',\n",
              " 'guys',\n",
              " 'half',\n",
              " 'ill',\n",
              " 'lot',\n",
              " 'sir',\n",
              " 'try',\n",
              " 'word',\n",
              " 'yo',\n",
              " 'account',\n",
              " 'birthday',\n",
              " 'car',\n",
              " 'dat',\n",
              " 'den',\n",
              " 'dinner',\n",
              " 'god',\n",
              " 'latest',\n",
              " 'luv',\n",
              " 'receive',\n",
              " 'trying',\n",
              " 'world',\n",
              " '150ppm',\n",
              " 'another',\n",
              " 'bad',\n",
              " 'bed',\n",
              " 'being',\n",
              " 'big',\n",
              " 'cool',\n",
              " 'liao',\n",
              " 'offer',\n",
              " 'once',\n",
              " 'real',\n",
              " 'shall',\n",
              " 'start',\n",
              " 'two',\n",
              " 'box',\n",
              " 'camera',\n",
              " 'eat',\n",
              " 'enjoy',\n",
              " 'fuck',\n",
              " 'girl',\n",
              " 'i.ll',\n",
              " 'landline',\n",
              " 'month',\n",
              " 'problem',\n",
              " 'reach',\n",
              " 'room',\n",
              " 'sweet',\n",
              " 'thanx',\n",
              " 'watching',\n",
              " 'wk',\n",
              " 'actually',\n",
              " 'awarded',\n",
              " 'baby',\n",
              " 'bring',\n",
              " 'cost',\n",
              " 'forgot',\n",
              " 'hear',\n",
              " 'important',\n",
              " 'jus',\n",
              " 'kiss',\n",
              " 'look',\n",
              " 'minutes',\n",
              " 'okay',\n",
              " 'pay',\n",
              " 'quite',\n",
              " 'remember',\n",
              " 'speak',\n",
              " 'till',\n",
              " 'video',\n",
              " 'wanted',\n",
              " '9',\n",
              " 'asked',\n",
              " 'between',\n",
              " 'bt',\n",
              " 'called',\n",
              " 'fun',\n",
              " 'g',\n",
              " 'lei',\n",
              " 'looking',\n",
              " 'might',\n",
              " 'orange',\n",
              " 'school',\n",
              " 'shopping',\n",
              " 'those',\n",
              " 'though',\n",
              " '>',\n",
              " 'afternoon',\n",
              " 'ah',\n",
              " 'aight',\n",
              " 'because',\n",
              " 'came',\n",
              " 'code',\n",
              " 'easy',\n",
              " 'entry',\n",
              " 'hour',\n",
              " 'little',\n",
              " 'maybe',\n",
              " 'part',\n",
              " 'plan',\n",
              " 'pm',\n",
              " 'show',\n",
              " 'shows',\n",
              " 'til',\n",
              " 'wif',\n",
              " 'without',\n",
              " '6',\n",
              " 'anyway',\n",
              " 'hav',\n",
              " 'made',\n",
              " 'makes',\n",
              " 'must',\n",
              " 'po',\n",
              " 'put',\n",
              " 'sat',\n",
              " 'selected',\n",
              " 'shit',\n",
              " 't',\n",
              " 'times',\n",
              " 'true',\n",
              " 'tv',\n",
              " 'until',\n",
              " 'while',\n",
              " 'working',\n",
              " 'boy',\n",
              " 'collect',\n",
              " 'coz',\n",
              " 'dad',\n",
              " 'details',\n",
              " 'enough',\n",
              " 'gift',\n",
              " 'goes',\n",
              " 'hair',\n",
              " 'leh',\n",
              " 'most',\n",
              " 'music',\n",
              " 'office',\n",
              " 'pain',\n",
              " 'plus',\n",
              " 're',\n",
              " 'says',\n",
              " 'texts',\n",
              " 'watch',\n",
              " 'weekend',\n",
              " 'wife',\n",
              " 'years',\n",
              " 'yours',\n",
              " 'å£1000',\n",
              " '2nd',\n",
              " 'alright',\n",
              " 'apply',\n",
              " 'bus',\n",
              " 'calls',\n",
              " 'dis',\n",
              " 'dude',\n",
              " 'else',\n",
              " 'evening',\n",
              " 'everything',\n",
              " 'food',\n",
              " 'lt;decimal&gt',\n",
              " 'means',\n",
              " 'network',\n",
              " 'old',\n",
              " 'pa',\n",
              " 'post',\n",
              " 'probably',\n",
              " 'rate',\n",
              " 'ringtone',\n",
              " 'run',\n",
              " 'shop',\n",
              " 'tones',\n",
              " 'town',\n",
              " 'wake',\n",
              " 'wid',\n",
              " 'å£100',\n",
              " '10p',\n",
              " '7',\n",
              " 'able',\n",
              " 'book',\n",
              " 'collection',\n",
              " 'double',\n",
              " 'ever',\n",
              " 'feeling',\n",
              " 'huh',\n",
              " 'hurt',\n",
              " 'left',\n",
              " 'messages',\n",
              " 'missing',\n",
              " 'plz',\n",
              " 'price',\n",
              " 'princess',\n",
              " 'sad',\n",
              " 'sexy',\n",
              " 't&cs',\n",
              " 'test',\n",
              " 'these',\n",
              " 'tmr',\n",
              " 'vouchers',\n",
              " 'worry',\n",
              " 'wot',\n",
              " 'xmas',\n",
              " 'yourself',\n",
              " \"'d\",\n",
              " '=',\n",
              " '\\\\',\n",
              " 'abt',\n",
              " 'beautiful',\n",
              " 'de',\n",
              " 'driving',\n",
              " 'either',\n",
              " 'haf',\n",
              " 'hot',\n",
              " 'juz',\n",
              " 'movie',\n",
              " 'noe',\n",
              " 'online',\n",
              " 'oso',\n",
              " 'rite',\n",
              " 'sch',\n",
              " 'since',\n",
              " 'took',\n",
              " 'update',\n",
              " 'valid',\n",
              " 'weekly',\n",
              " '10',\n",
              " '500',\n",
              " 'award',\n",
              " 'away',\n",
              " 'bored',\n",
              " 'change',\n",
              " 'close',\n",
              " 'comes',\n",
              " 'dreams',\n",
              " 'drop',\n",
              " 'forget',\n",
              " 'full',\n",
              " 'goin',\n",
              " 'gr8',\n",
              " 'head',\n",
              " 'hours',\n",
              " 'join',\n",
              " 'making',\n",
              " 'missed',\n",
              " 'needs',\n",
              " 'open',\n",
              " 'order',\n",
              " 'ring',\n",
              " 'sae',\n",
              " 'saying',\n",
              " 'sleeping',\n",
              " 'started',\n",
              " 'sun',\n",
              " 'taking',\n",
              " 'together',\n",
              " 'tomo',\n",
              " 'type',\n",
              " 'walk',\n",
              " 'xxx',\n",
              " 'å£5000',\n",
              " '$',\n",
              " '8',\n",
              " 'answer',\n",
              " 'await',\n",
              " 'both',\n",
              " 'calling',\n",
              " 'club',\n",
              " 'dating',\n",
              " 'delivery',\n",
              " 'eve',\n",
              " 'face',\n",
              " 'family',\n",
              " 'final',\n",
              " 'game',\n",
              " 'gone',\n",
              " 'guy',\n",
              " 'happen',\n",
              " 'hard',\n",
              " 'leaving',\n",
              " 'mail',\n",
              " 'mom',\n",
              " 'national',\n",
              " 'okie',\n",
              " 'parents',\n",
              " 'row',\n",
              " 'saw',\n",
              " 'services',\n",
              " 'smiling',\n",
              " 'snow',\n",
              " 'stay',\n",
              " 'story',\n",
              " 'ta',\n",
              " 'thank',\n",
              " 'top',\n",
              " 'tried',\n",
              " 'trip',\n",
              " 'uk',\n",
              " 'wen',\n",
              " 'words',\n",
              " '8007',\n",
              " ':-(',\n",
              " 'ard',\n",
              " 'attempt',\n",
              " 'believe',\n",
              " 'blue',\n",
              " 'boytoy',\n",
              " 'charge',\n",
              " 'colour',\n",
              " 'congrats',\n",
              " 'father',\n",
              " 'found',\n",
              " 'frm',\n",
              " 'happened',\n",
              " 'kind',\n",
              " 'listen',\n",
              " 'mates',\n",
              " 'mine',\n",
              " 'minute',\n",
              " 'mob',\n",
              " 'neva',\n",
              " 'nite',\n",
              " 'opt',\n",
              " 'oredi',\n",
              " 'pobox',\n",
              " 'points',\n",
              " 'poly',\n",
              " 'pub',\n",
              " 'search',\n",
              " 'second',\n",
              " 'seeing',\n",
              " 'set',\n",
              " 'smoke',\n",
              " 't&c',\n",
              " 'takes',\n",
              " 'tel',\n",
              " 'tho',\n",
              " 'touch',\n",
              " 'worth',\n",
              " 'www',\n",
              " '||',\n",
              " 'å£1.50',\n",
              " 'å£2000',\n",
              " \"''\",\n",
              " '750',\n",
              " '86688',\n",
              " ':-)',\n",
              " 'address',\n",
              " 'angry',\n",
              " 'anyone',\n",
              " 'auction',\n",
              " 'awesome',\n",
              " 'busy',\n",
              " 'carlos',\n",
              " 'choose',\n",
              " 'date',\n",
              " 'drink',\n",
              " 'email',\n",
              " 'fr',\n",
              " 'games',\n",
              " 'gd',\n",
              " 'girls',\n",
              " 'hee',\n",
              " 'hungry',\n",
              " 'john',\n",
              " 'lose',\n",
              " 'pics',\n",
              " 'project',\n",
              " 'question',\n",
              " 'reason',\n",
              " 'savamob',\n",
              " 'sis',\n",
              " 'ten',\n",
              " 'thinking',\n",
              " 'thinks',\n",
              " 'todays',\n",
              " 'tot',\n",
              " 'unsubscribe',\n",
              " 'used',\n",
              " 'voucher',\n",
              " 'wants',\n",
              " 'whatever',\n",
              " 'whole',\n",
              " 'å£500',\n",
              " '12hrs',\n",
              " 'aft',\n",
              " 'bank',\n",
              " 'break',\n",
              " 'brother',\n",
              " 'cause',\n",
              " 'company',\n",
              " 'confirm',\n",
              " 'congratulations',\n",
              " 'content',\n",
              " 'decided',\n",
              " 'die',\n",
              " 'enter',\n",
              " 'everyone',\n",
              " 'exam',\n",
              " 'expires',\n",
              " 'far',\n",
              " 'fast',\n",
              " 'felt',\n",
              " 'finished',\n",
              " 'happiness',\n",
              " 'invited',\n",
              " 'land',\n",
              " 'lesson',\n",
              " 'lets',\n",
              " 'lots',\n",
              " 'lucky',\n",
              " 'mayb',\n",
              " 'mean',\n",
              " 'mobileupd8',\n",
              " 'mum',\n",
              " 'news',\n",
              " 'offers',\n",
              " 'pounds',\n",
              " 'private',\n",
              " 'saturday',\n",
              " 'secret',\n",
              " 'sounds',\n",
              " 'understand',\n",
              " 'yesterday',\n",
              " 'å£250',\n",
              " '87066',\n",
              " 'age',\n",
              " 'ans',\n",
              " 'anytime',\n",
              " 'ass',\n",
              " 'available',\n",
              " 'bathe',\n",
              " 'bonus',\n",
              " 'chikku',\n",
              " 'crazy',\n",
              " 'difficult',\n",
              " 'discount',\n",
              " 'download',\n",
              " 'drive',\n",
              " 'each',\n",
              " 'empty',\n",
              " 'etc',\n",
              " 'freemsg',\n",
              " 'friday',\n",
              " 'friendship',\n",
              " 'gets',\n",
              " 'hand',\n",
              " 'hmm',\n",
              " 'identifier',\n",
              " 'im',\n",
              " 'joy',\n",
              " 'log',\n",
              " 'lovely',\n",
              " 'loving',\n",
              " 'ltd',\n",
              " 'luck',\n",
              " 'march',\n",
              " 'motorola',\n",
              " 'mrng',\n",
              " 'nope',\n",
              " 'operator',\n",
              " 'outside',\n",
              " 'party',\n",
              " 'phones',\n",
              " 'plans',\n",
              " 'remove',\n",
              " 'rs',\n",
              " 'sending',\n",
              " 'shower',\n",
              " 'sister',\n",
              " 'statement',\n",
              " 'suite342/2lands',\n",
              " 'supposed',\n",
              " 'talking',\n",
              " 'their',\n",
              " 'un',\n",
              " 'visit',\n",
              " 'weeks',\n",
              " 'welcome',\n",
              " 'wil',\n",
              " 'wit',\n",
              " 'wonderful',\n",
              " 'wow',\n",
              " '\\x89û',\n",
              " '.....',\n",
              " '08000839402',\n",
              " '2003',\n",
              " '800',\n",
              " '@',\n",
              " 'admirer',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'balance',\n",
              " 'bslvyl',\n",
              " 'card',\n",
              " 'chennai',\n",
              " 'christmas',\n",
              " 'college',\n",
              " 'complimentary',\n",
              " 'couple',\n",
              " 'crave',\n",
              " 'credit',\n",
              " 'cut',\n",
              " 'darlin',\n",
              " 'earlier',\n",
              " 'eg',\n",
              " 'ends',\n",
              " 'england',\n",
              " 'ex',\n",
              " 'extra',\n",
              " 'fancy',\n",
              " 'fri',\n",
              " 'gas',\n",
              " 'grins',\n",
              " 'hit',\n",
              " 'ho',\n",
              " 'information',\n",
              " 'kids',\n",
              " 'knew',\n",
              " 'lost',\n",
              " 'mate',\n",
              " 'mobiles',\n",
              " 'monday',\n",
              " 'msgs',\n",
              " 'ntt',\n",
              " 'numbers',\n",
              " 'oops',\n",
              " 'orchard',\n",
              " 'picking',\n",
              " 'player',\n",
              " 'pretty',\n",
              " 'prob',\n",
              " 'reached',\n",
              " 'redeemed',\n",
              " 'reward',\n",
              " 'save',\n",
              " 'sea',\n",
              " 'sex',\n",
              " 'side',\n",
              " 'slow',\n",
              " 'small',\n",
              " 'sort',\n",
              " 'support',\n",
              " 'tc',\n",
              " 'through',\n",
              " 'tickets',\n",
              " 'trust',\n",
              " 'txts',\n",
              " 'uncle',\n",
              " 'unlimited',\n",
              " 'valentine',\n",
              " 'w',\n",
              " 'wana',\n",
              " 'whenever',\n",
              " 'within',\n",
              " 'wkly',\n",
              " 'wonder',\n",
              " '\\x89ûò',\n",
              " 'å£350',\n",
              " '08000930705',\n",
              " '100',\n",
              " '20p',\n",
              " 'al',\n",
              " 'area',\n",
              " 'askd',\n",
              " 'asking',\n",
              " \"b'day\",\n",
              " 'b4',\n",
              " 'bb',\n",
              " 'bill',\n",
              " 'bout',\n",
              " 'brings',\n",
              " 'callertune',\n",
              " 'case',\n",
              " 'charged',\n",
              " 'cheap',\n",
              " 'comp',\n",
              " 'copy',\n",
              " 'correct',\n",
              " 'course',\n",
              " 'cs',\n",
              " 'dogging',\n",
              " 'don',\n",
              " 'dream',\n",
              " 'eh',\n",
              " 'f',\n",
              " 'fact',\n",
              " 'finally',\n",
              " 'freephone',\n",
              " 'frnds',\n",
              " 'gave',\n",
              " 'gettin',\n",
              " 'gt',\n",
              " 'gym',\n",
              " 'heard',\n",
              " 'india',\n",
              " 'info',\n",
              " 'k.',\n",
              " 'kate',\n",
              " 'laptop',\n",
              " 'less',\n",
              " 'lessons',\n",
              " 'light',\n",
              " 'loads',\n",
              " 'loved',\n",
              " 'match',\n",
              " 'meant',\n",
              " 'moment',\n",
              " 'months',\n",
              " 'move',\n",
              " 'mu',\n",
              " 'muz',\n",
              " 'nah',\n",
              " 'net',\n",
              " 'ni8',\n",
              " 'nyt',\n",
              " 'paper',\n",
              " 'pic',\n",
              " 'point',\n",
              " 'police',\n",
              " 'quiz',\n",
              " 'reaching',\n",
              " 'reading',\n",
              " 'rock',\n",
              " 'rply',\n",
              " 's.',\n",
              " 'slowly',\n",
              " 'smth',\n",
              " 'st',\n",
              " 'staying',\n",
              " 'summer',\n",
              " 'telling',\n",
              " 'th',\n",
              " 'tonite',\n",
              " 'treat',\n",
              " 'ts&cs',\n",
              " 'ugh',\n",
              " 'unless',\n",
              " 'warm',\n",
              " 'wine',\n",
              " 'winner',\n",
              " 'wishing',\n",
              " 'woke',\n",
              " 'wondering',\n",
              " 'worries',\n",
              " 'wrong',\n",
              " 'xx',\n",
              " 'yr',\n",
              " '#',\n",
              " '0800',\n",
              " '0870',\n",
              " '11',\n",
              " '2day',\n",
              " 'abiola',\n",
              " 'accept',\n",
              " 'ar',\n",
              " 'bcoz',\n",
              " 'booked',\n",
              " 'boss',\n",
              " 'buzz',\n",
              " 'camcorder',\n",
              " 'catch',\n",
              " 'cd',\n",
              " 'checking',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eVYZ_qIzLGU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ed350b5-4bf6-48a2-8f8e-669b2a0a4b0f"
      },
      "source": [
        "# check if gpu is enabled\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFS1xrF9zRe8"
      },
      "source": [
        "# batch gradient decent - sort key to ensure during padding each sentences in each batch to be the same size\n",
        "train_iter, test_iter = ttd.Iterator.splits((train_dataset, test_dataset), sort_key = lambda x: len(x.data), batch_sizes = (32,256), device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vXkw2SQzoTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79d07c2e-71b2-4549-e598-e61cc49355c2"
      },
      "source": [
        "# checking batch shapes for input \n",
        "for inputs, targets in train_iter:\n",
        "  print(\"inputs:\", inputs, \"shape\", inputs.shape)\n",
        "  print(\"targets:\", targets, \"shape\", targets.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[   1,    1,    1,  ...,   76,  211,  301],\n",
            "        [   1,    1,    1,  ..., 3553, 4643, 1854],\n",
            "        [   1,    1,    1,  ...,   36,  211,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   30, 7570,    2],\n",
            "        [   1,    1,    1,  ...,  117,  404,  167],\n",
            "        [   1,    1,    1,  ...,   19, 6748,   21]], device='cuda:0') shape torch.Size([32, 88])\n",
            "targets: tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   12,   31,  149],\n",
            "        [   1,    1,    1,  ...,   71,   24,    2],\n",
            "        [   8,  462,  940,  ...,  254,  950,   73],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  615, 5279,   10],\n",
            "        [   1,    1,    1,  ...,   21,  758,    7],\n",
            "        [   1,    1,    1,  ...,   45,   39,  275]], device='cuda:0') shape torch.Size([32, 116])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   30,    5,    7],\n",
            "        [   1,    1,    1,  ...,   60,    4,  516],\n",
            "        [   1,    1,    1,  ...,   47,  440,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  214,    4, 2735],\n",
            "        [   1,    1,    1,  ...,  120,   16,   21],\n",
            "        [   1,    1,    1,  ...,  165, 1254,    2]], device='cuda:0') shape torch.Size([32, 52])\n",
            "targets: tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 4249,  591,  231],\n",
            "        [   1,    1,    1,  ...,    1, 4964, 4606],\n",
            "        [ 150,  188,    6,  ...,  262,   18,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 3604,    2, 3133],\n",
            "        [   1,    1,    1,  ...,    6,  180,    7],\n",
            "        [   1,    1,    1,  ...,  693,  683,    7]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    9,  188, 1013],\n",
            "        [   1,    1,    1,  ...,  249,  106,   11],\n",
            "        [   1,    1,    1,  ...,    9,  345,   68],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   81,  553,    7],\n",
            "        [   1,    1,    1,  ..., 1644, 7708, 6393],\n",
            "        [   1,    1,    1,  ..., 3554,  488,    2]], device='cuda:0') shape torch.Size([32, 102])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
            "        1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   52, 3444,    2],\n",
            "        [   1,    1,    1,  ..., 6139, 4930,  193],\n",
            "        [   1,    1,    1,  ...,   43,   18,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  340, 1676,   21],\n",
            "        [   1,    1,    1,  ...,  764,   94,   11],\n",
            "        [   1,    1,    1,  ...,  274, 5346,   16]], device='cuda:0') shape torch.Size([32, 49])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    2,    2,    2],\n",
            "        [   1,    1,    1,  ...,   21, 6063,   21],\n",
            "        [   1,    1,    1,  ...,   13, 1943,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   13, 1721,  231],\n",
            "        [   1,    1,    1,  ...,    1,   63,    2],\n",
            "        [   1,    1,    1,  ..., 4506, 1700,   29]], device='cuda:0') shape torch.Size([32, 157])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    4,  213, 6780],\n",
            "        [   1,    1,    1,  ...,   26,   28, 3646],\n",
            "        [   1,    1,    1,  ...,  183, 1334,  400],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    8,  575,  481],\n",
            "        [   1,    1,    1,  ...,    1, 3729, 3698],\n",
            "        [   1,    1,    1,  ...,    6, 2837,   28]], device='cuda:0') shape torch.Size([32, 37])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[ 122,   51,    2,  ...,   37,  699, 1126],\n",
            "        [   1,    1,    1,  ...,   19,   69,  605],\n",
            "        [   1,    1,    1,  ...,   19,    5,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  981,  155,    2],\n",
            "        [   1,    1,    1,  ...,    3, 1944,   11],\n",
            "        [   1,    1,    1,  ...,  380, 3639, 2566]], device='cuda:0') shape torch.Size([32, 42])\n",
            "targets: tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  153,    4, 2173],\n",
            "        [   1,    1,    1,  ...,   85,   16, 7728],\n",
            "        [   1,    1,    1,  ...,  255, 7287,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  111, 2067,   10],\n",
            "        [   1,    1,    1,  ...,  318,   10,   10],\n",
            "        [   1,    1,    1,  ...,   22,    8, 6894]], device='cuda:0') shape torch.Size([32, 89])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    2, 1673, 3596],\n",
            "        [   1,    1,    1,  ...,   50,    5, 6989],\n",
            "        [   1,    1,    1,  ..., 1891,   71,   52],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  262,   42,   66],\n",
            "        [   1,    1,    1,  ...,    9, 5196, 4853],\n",
            "        [   1,    1,    1,  ...,  123,  155,  150]], device='cuda:0') shape torch.Size([32, 39])\n",
            "targets: tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   47,  162,   11],\n",
            "        [   1,    1,    1,  ...,    9,  284,    2],\n",
            "        [   1,    1,    1,  ...,    9,  633,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   71,   32, 5443],\n",
            "        [  75,   65,   18,  ...,   40,   12,   10],\n",
            "        [   1,    1,    1,  ...,  890,  302,  211]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  400, 1130,   73],\n",
            "        [   1,    1,    1,  ..., 2003,  164,   11],\n",
            "        [   1,    1,    1,  ..., 2703,  160,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  212,   78,    2],\n",
            "        [   1,    1,    1,  ...,  105,  110,    2],\n",
            "        [   1,    1,    1,  ..., 6010,   12,  106]], device='cuda:0') shape torch.Size([32, 45])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   19,  605,  178],\n",
            "        [   1,    1,    1,  ...,  186, 6945,    2],\n",
            "        [   1,    1,    1,  ...,   37,  267,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   52,   86,    2],\n",
            "        [   1,    1,    1,  ..., 1099,   96,  151],\n",
            "        [   1,    1,    1,  ...,  629,   12,   10]], device='cuda:0') shape torch.Size([32, 76])\n",
            "targets: tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    9, 2160,  382],\n",
            "        [   1,    1,    1,  ...,  743,  179,   24],\n",
            "        [   1,    1,    1,  ..., 3364,   41,  173],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    3, 2648,    2],\n",
            "        [   1,    1,    1,  ...,   34,   17, 2762],\n",
            "        [   1,    1,    1,  ...,    4,  275,   11]], device='cuda:0') shape torch.Size([32, 166])\n",
            "targets: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[ 884, 1907,    2,  ..., 2046, 1661,    2],\n",
            "        [   1,    1,    1,  ...,  646,    2, 3003],\n",
            "        [   1,    1,    1,  ...,   36,  385,  570],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   15,    8,  295],\n",
            "        [   1,    1,    1,  ...,    9,   80,    2],\n",
            "        [   1,    1,    1,  ..., 1738, 1072, 1513]], device='cuda:0') shape torch.Size([32, 56])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   14, 7664, 1085],\n",
            "        [   1,    1,    1,  ...,  332, 1313,   11],\n",
            "        [   1,    1,    1,  ...,  111,  338,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  120,  108,    2],\n",
            "        [   1,    1,    1,  ...,   60,   19,  222],\n",
            "        [   1,    1,    1,  ..., 2835,  188,    7]], device='cuda:0') shape torch.Size([32, 102])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 1100, 2884,    7],\n",
            "        [   1,    1,    1,  ...,  763,    4, 1482],\n",
            "        [   1,    1,    1,  ...,  596,  194,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  110,  703,    2],\n",
            "        [   1,    1,    1,  ...,   12,   11,  829],\n",
            "        [   1,    1,    1,  ...,  103,  413,   16]], device='cuda:0') shape torch.Size([32, 78])\n",
            "targets: tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   76,  162,    2],\n",
            "        [  54,    3,   46,  ...,    4,  318,    2],\n",
            "        [   1,    1,    1,  ...,   81,  268,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   14,  277,    2],\n",
            "        [   1,    1,    1,  ...,  316, 2021, 6907],\n",
            "        [   1,    1,    1,  ...,   37,   40,  245]], device='cuda:0') shape torch.Size([32, 95])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   37,  267,    2],\n",
            "        [   1,    1,    1,  ..., 5218, 1513,    7],\n",
            "        [   1,    1,    1,  ..., 1672,  471,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    2,  221,    2],\n",
            "        [   1,    1,    1,  ...,   85,  244, 4111],\n",
            "        [   1,    1,    1,  ...,   22,    9,  381]], device='cuda:0') shape torch.Size([32, 53])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 3205,   23,    7],\n",
            "        [   1,    1,    1,  ...,   11,   87,  237],\n",
            "        [   1,    1,    1,  ...,   26,   28, 3617],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   43,   94,   11],\n",
            "        [   1,    1,    1,  ...,   13, 2244,    2],\n",
            "        [ 318,    2,    3,  ...,    4,  196,   11]], device='cuda:0') shape torch.Size([32, 62])\n",
            "targets: tensor([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  642,    7,  637],\n",
            "        [   1,    1,    1,  ...,  110, 3332,    7],\n",
            "        [   1,    1,    1,  ...,   15,  425,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 6286,  198,    7],\n",
            "        [   1,    1,    1,  ...,    3,  296,   37],\n",
            "        [   1,    1,    1,  ...,  254,  951,   73]], device='cuda:0') shape torch.Size([32, 44])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   13,  495,  682],\n",
            "        [  23,  717,    5,  ...,  179,  181,    2],\n",
            "        [   1,    1,    1,  ...,    4,   16,  315],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 4398, 1422,    2],\n",
            "        [   1,    1,    1,  ..., 3313,   37, 1213],\n",
            "        [   1,    1,    1,  ...,    9, 2680,    2]], device='cuda:0') shape torch.Size([32, 86])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[  23,   53,  664,  ...,   12,   11,  829],\n",
            "        [   1,    1,    1,  ...,   89,   10,   10],\n",
            "        [   1,    1,    1,  ...,   80,  289,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 3007,  847,   10],\n",
            "        [   1,    1,    1,  ...,  560,  720,   83],\n",
            "        [   1,    1,    1,  ...,   19,  352,    7]], device='cuda:0') shape torch.Size([32, 39])\n",
            "targets: tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 3082, 1711,    7],\n",
            "        [   1,    1,    1,  ...,  275,  863,    2],\n",
            "        [   1,    1,    1,  ...,  596,  194,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   63,   94,    2],\n",
            "        [   1,    1,    1,  ...,  191,   83,   10],\n",
            "        [   1,    1,    1,  ...,  109,  292,    2]], device='cuda:0') shape torch.Size([32, 44])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   50,  210,  294],\n",
            "        [   1,    1,    1,  ..., 1232,   67,   80],\n",
            "        [   1,    1,    1,  ...,  100,  325,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  188,   29,    7],\n",
            "        [   1,    1,    1,  ...,   52, 1563,    2],\n",
            "        [   1,    1,    1,  ...,   22, 1766,    2]], device='cuda:0') shape torch.Size([32, 40])\n",
            "targets: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  817,  125,    2],\n",
            "        [   1,    1,    1,  ...,  188,   94,   11],\n",
            "        [   1,    1,    1,  ...,  441,  409,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   41,  537,    7],\n",
            "        [   1,    1,    1,  ...,   47, 1165,   11],\n",
            "        [   1,    1,    1,  ...,    9, 5766,    2]], device='cuda:0') shape torch.Size([32, 40])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   91,   26,  128],\n",
            "        [   1,    1,    1,  ..., 6567,  147,    2],\n",
            "        [   1,    1,    1,  ...,    1,    1,   63],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  102,   48,  688],\n",
            "        [   1,    1,    1,  ..., 4351,   61, 5856],\n",
            "        [   1,    1,    1,  ...,  798,  591,   10]], device='cuda:0') shape torch.Size([32, 60])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  629,    5,   10],\n",
            "        [   1,    1,    1,  ...,   12,   94,   11],\n",
            "        [   1,    1,    1,  ...,  835,  577, 7372],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   22,   24,  170],\n",
            "        [   1,    1,    1,  ...,  675,    2, 2948],\n",
            "        [   1,    1,    1,  ...,   78,   34,  384]], device='cuda:0') shape torch.Size([32, 35])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  347,  155,    2],\n",
            "        [ 318,    6, 6971,  ...,  255,  332,    2],\n",
            "        [   1,    1,    1,  ...,   28,  255,  170],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1330,  521,    7],\n",
            "        [   1,    1,    1,  ...,   15,   99,   11],\n",
            "        [   1,    1,    1,  ..., 1564,  193, 2331]], device='cuda:0') shape torch.Size([32, 43])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   15, 7547,    7],\n",
            "        [   1,    1,    1,  ..., 2944, 5291,  212],\n",
            "        [ 645,   10,  181,  ...,  203,   68,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   20, 6383,    2],\n",
            "        [   1,    1,    1,  ...,  269, 1635, 7727],\n",
            "        [   1,    1,    1,  ...,    5,   28, 5280]], device='cuda:0') shape torch.Size([32, 40])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  206, 2037,   11],\n",
            "        [   1,    1,    1,  ..., 2516,  366,    2],\n",
            "        [   1,    1,    1,  ...,  255,  108,    2],\n",
            "        ...,\n",
            "        [   1, 3710,   76,  ...,   21, 1274,   66],\n",
            "        [   1,    1,    1,  ...,   87, 7755, 4646],\n",
            "        [   1,    1,    1,  ...,   37,  273,    2]], device='cuda:0') shape torch.Size([32, 48])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    2,  254,  950],\n",
            "        [   1,    1,    1,  ..., 7100,  269, 7403],\n",
            "        [   1,    1,    1,  ...,   79,  791,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  404,   16,    2],\n",
            "        [   1,    1,    1,  ...,   30,    5,    7],\n",
            "        [   1,    1,    1,  ...,  688,  423,   10]], device='cuda:0') shape torch.Size([32, 68])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    2,   33, 6847],\n",
            "        [   1,    1,    1,  ..., 1024,   94,    2],\n",
            "        [   1,    1,    1,  ...,  697,  547,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  543, 1749,   21],\n",
            "        [   1,    1,    1,  ...,   20,  138,    7],\n",
            "        [   1,    1,    1,  ...,   40,   78,   38]], device='cuda:0') shape torch.Size([32, 112])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   47,  952,    7],\n",
            "        [   1,    1,    1,  ...,   19, 5254,   11],\n",
            "        [   1,    1,    1,  ...,   28,   17,  153],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  281,  566,   11],\n",
            "        [   1,    1,    1,  ...,   11,  147,  844],\n",
            "        [   1,    1,    1,  ..., 1975,    2, 3784]], device='cuda:0') shape torch.Size([32, 41])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   86,  254, 1058],\n",
            "        [   1,    1,    1,  ...,  240,  471,    2],\n",
            "        [   1,    1,    1,  ...,   63,   94,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    9, 1007,  126],\n",
            "        [   1,    1,    1,  ..., 5993,   60,  141],\n",
            "        [   1,    1,    1,  ..., 6651,    9,  905]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   66,  254,  951],\n",
            "        [   1,    1,    1,  ...,   38,  368,    2],\n",
            "        [  30,    5,  134,  ...,   55,  398,   55],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 5555,   22,  182],\n",
            "        [   1,    1,    1,  ..., 2166,   97, 3377],\n",
            "        [   1,    1,    1,  ...,   41, 4613,    7]], device='cuda:0') shape torch.Size([32, 40])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 1, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  358, 5102,  260],\n",
            "        [   1,    1,    1,  ...,   89,   34,    7],\n",
            "        [   1,    1,    1,  ...,  369, 1727,    2],\n",
            "        ...,\n",
            "        [  19,    9,  238,  ...,   27,   64,   36],\n",
            "        [   1,    1,    1,  ...,  176, 4422,    2],\n",
            "        [   1,    1,    1,  ...,   37, 5948,    2]], device='cuda:0') shape torch.Size([32, 56])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 2810,  150,    2],\n",
            "        [   1,    1,    1,  ...,  117, 1416,    2],\n",
            "        [   1,    1,    1,  ..., 1207,  293,  293],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1748,    9,  489],\n",
            "        [   1,    1,    1,  ...,   67,  484,    2],\n",
            "        [  23,   53, 5424,  ...,  216,   84,  318]], device='cuda:0') shape torch.Size([32, 46])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   31, 6173,    2],\n",
            "        [   1,    1,    1,  ...,   15,    8,  295],\n",
            "        [   1,    1,    1,  ..., 1257,   96,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   26,  895,   29],\n",
            "        [   1,    1,    1,  ...,  881,  238,    7],\n",
            "        [   1,    1,    1,  ...,  316,   86,    2]], device='cuda:0') shape torch.Size([32, 43])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 5271, 7463, 5500],\n",
            "        [   1,    1,    1,  ...,  118,  616,    7],\n",
            "        [   1,    1,    1,  ..., 3261,   18,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 3439, 2199,    7],\n",
            "        [   1,    1,    1,  ...,    8,   79,  125],\n",
            "        [   1,    1,    1,  ...,  433,  445,    2]], device='cuda:0') shape torch.Size([32, 187])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[  1,   1,   1,  ...,  33, 400,  72],\n",
            "        [  1,   1,   1,  ...,   8, 691,   2],\n",
            "        [  1,   1,   1,  ...,  19, 284,   2],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,  95,  15, 494],\n",
            "        [  1,   1,   1,  ...,   8, 899, 235],\n",
            "        [  1,   1,   1,  ..., 176,  29,   7]], device='cuda:0') shape torch.Size([32, 37])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  150,   63,   21],\n",
            "        [   1,    1,    1,  ...,   90,    8,  170],\n",
            "        [   1,    1,    1,  ...,  224, 2293,   89],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   20,  130,    7],\n",
            "        [   1,    1,    1,  ...,   64,   36,    2],\n",
            "        [   1,    1,    1,  ...,  165,  298,    7]], device='cuda:0') shape torch.Size([32, 41])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   41,   45,  137],\n",
            "        [   1,    1,    1,  ...,  139,  111,    2],\n",
            "        [   1, 2055,    2,  ..., 5092,    5,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    3,  394,   21],\n",
            "        [   1,    1,    1,  ...,  677,   76,  162],\n",
            "        [   3,   92,  136,  ..., 3897,    2,   66]], device='cuda:0') shape torch.Size([32, 44])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  454,   75, 1273],\n",
            "        [   1,    1,    1,  ..., 1683,  256,    2],\n",
            "        [   1,    1,    1,  ...,  275,   18,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    6, 2980,  230],\n",
            "        [   1,    1,    1,  ...,  120,  289, 3295],\n",
            "        [   1,    1,    1,  ...,  154,    2,  989]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  339,  568,    7],\n",
            "        [   1,    1,    1,  ...,  269,  155,   14],\n",
            "        [   1,    1,    1,  ..., 3313,   37, 1213],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    2,  657,   11],\n",
            "        [   1,    1,    1,  ...,  634,   12,   39],\n",
            "        [   1,    1,    1,  ...,  553, 1765,    7]], device='cuda:0') shape torch.Size([32, 41])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 1260, 1741,  282],\n",
            "        [   1,    1,    1,  ...,   72,   84,  318],\n",
            "        [   1,    1,    1,  ...,  624,   10,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  488, 2339,   34],\n",
            "        [   1,    1,    1,  ...,   91,   26,  128],\n",
            "        [   1,    1,    1,  ...,    9, 4292, 4541]], device='cuda:0') shape torch.Size([32, 45])\n",
            "targets: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   21, 5673,   21],\n",
            "        [   1,    1,    1,  ...,   17,  298,   11],\n",
            "        [   1,    1,    1,  ...,  133,  120,   21],\n",
            "        ...,\n",
            "        [   1,   17,  201,  ..., 5252,   66,   21],\n",
            "        [   1,    1,    1,  ...,  126,  254,  951],\n",
            "        [   1,    1,    1,  ...,    3,   92,    2]], device='cuda:0') shape torch.Size([32, 42])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    2,  254,  794],\n",
            "        [   1,    1,    1,  ...,    4, 1558,  322],\n",
            "        [   1,    1,    1,  ..., 3572,  504,   66],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    2,  314,   10],\n",
            "        [   1,    1,    1,  ..., 1994, 3143,    7],\n",
            "        [   1,    1,    1,  ...,  254, 6217,   55]], device='cuda:0') shape torch.Size([32, 44])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    3,  410,    2],\n",
            "        [   1,    1,    1,  ...,   12, 1150,   11],\n",
            "        [   1,    1,    1,  ...,  120,  232,  858],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  102,   78,   10],\n",
            "        [   1,    1,    1,  ...,  438,    6, 1651],\n",
            "        [  18,   31, 2040,  ...,  188, 1622,    2]], device='cuda:0') shape torch.Size([32, 71])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 3374,   94,   11],\n",
            "        [   1,    1,    1,  ...,  320,  128,    2],\n",
            "        [   1,    1,    1,  ...,    7,  420,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  134,  348,  148],\n",
            "        [   1,    1,    1,  ...,  110,  935,   11],\n",
            "        [   1,    1,    1,  ...,   12,   29,    7]], device='cuda:0') shape torch.Size([32, 55])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   50,  792,  199],\n",
            "        [   1,    1,    1,  ...,    4,  114, 2866],\n",
            "        [   1,    1,    1,  ...,  232,  271,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   19,    8,  632],\n",
            "        [   1,    1,    1,  ..., 2337,   29,   10],\n",
            "        [   1,    1,    1,  ..., 5549,    2, 5410]], device='cuda:0') shape torch.Size([32, 60])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   16,   67,  138],\n",
            "        [   1,    1,    1,  ...,  159,    5,  115],\n",
            "        [   1,    1,    1,  ..., 7113,   73,   73],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  143,    5,   38],\n",
            "        [   1,    1,    1,  ...,  301,  669, 3457],\n",
            "        [   1,    1,    1,  ...,  140,  433,    7]], device='cuda:0') shape torch.Size([32, 148])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    4, 1716,    2],\n",
            "        [   1,    1,    1,  ...,  212,   95, 2446],\n",
            "        [   1,    1,    1,  ...,   25,    9, 2219],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 7688,  315,   11],\n",
            "        [   1,    1,    1,  ...,    8,  812,    7],\n",
            "        [   1,    1,    1,  ..., 5817,  400,    2]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   97,  282,  263],\n",
            "        [   1,    1,    1,  ...,  108,    4,  289],\n",
            "        [   1,    1,    1,  ...,   11,  386,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,  386,   11],\n",
            "        [   1,    1,    1,  ...,  114,  193,    2],\n",
            "        [   1,    1,    1,  ...,   91,   93, 2073]], device='cuda:0') shape torch.Size([32, 74])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  442,  172,    7],\n",
            "        [   1,    1,    1,  ...,    4,   40, 6008],\n",
            "        [   1,    1,    1,  ..., 1315, 1084,  493],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   48,   82,  854],\n",
            "        [   1,    1,    1,  ...,   17, 5825,    2],\n",
            "        [   1,    1,    1,  ...,  145,  481,    2]], device='cuda:0') shape torch.Size([32, 70])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  215,   18,  223],\n",
            "        [   1,    1,    1,  ...,   14,   18,    7],\n",
            "        [   1,    1,    1,  ...,  302,  211,    2],\n",
            "        ...,\n",
            "        [3850,   62, 4093,  ...,   32, 1928,    2],\n",
            "        [   1,    1,    1,  ...,  138,   22,  232],\n",
            "        [   1,    1,    1,  ...,   18,   68,   72]], device='cuda:0') shape torch.Size([32, 36])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  142,    9,   26],\n",
            "        [   1,    1,    1,  ...,   26, 3548,    2],\n",
            "        [   1,    1,    1,  ..., 1100, 2884,   21],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  997,  198,   10],\n",
            "        [   1,    1,    1,  ..., 5776,   73,   73],\n",
            "        [   1,    1,    1,  ...,   61, 2284,  661]], device='cuda:0') shape torch.Size([32, 107])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   14, 2280,    2],\n",
            "        [   1,    1,    1,  ...,  128,  271,    7],\n",
            "        [   1,    1,    1,  ...,  111,   72,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  109, 1789, 1140],\n",
            "        [   1,    1,    1,  ...,   25,   18,    7],\n",
            "        [   1,    1,    1,  ...,    8,  145,  173]], device='cuda:0') shape torch.Size([32, 41])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,  389,    3, 1958,   17,  500, 1453,\n",
            "           21,   29,    3,  207, 4359,   38, 5918],\n",
            "        [ 534,   72,  139,  111, 4423,  315,   11, 1504,  128,    3,   81,  100,\n",
            "          177,  315,   11,  747,  139,  111,  656,  667, 3161,  139,  111,   75,\n",
            "          110,  262, 6878,  442,  139,  111,   11],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,  206,\n",
            "           71,  357, 2077,  223,    7,   42,  281],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,   25,    8,   79,  494,   10, 1769],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1, 7413,    6,   57,   30,    5,  176,    2,   52,   14,   49,  977,\n",
            "            5,    8,  145,   80,    2,  989,    2],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,   97,    9,  153,    6,  129, 6670,  129,   14,    4,\n",
            "          185,  223,    2, 6055,   23,   53,  260],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "         1276,   21,  143,   30,    5,  148,   21],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,  795,   35,    3,\n",
            "           91,  213,  104,   32,  556,   28,  847,  403,  329,   94,  196, 6086,\n",
            "          707,   75,  952,   15,  110, 2124,  682],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1, 4247,   10,\n",
            "            3, 6014, 7765,   10,  143,   30,    5,    7,    3,   25,    4,   59,\n",
            "           13, 1436,   17,  284,   38,  302,   11],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,  150,  168,    3,   39,  405,  101,   32,   12,   54,   10,  783,\n",
            "            2,   88,   12,   43,   33,  693,    7],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,  528,    6,\n",
            "           14,   20, 5721, 6876,   41, 3062,    7],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    3, 4883, 1827,   84,  209, 2881],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           63,    2,    2,   29,    3,   77,   15,  489,    2,    2,   48,    3,\n",
            "           81,  264,    3,   44,   81, 2139,  178],\n",
            "        [  69,  885, 2839, 1692, 1010,   32,   20,  119,  101, 1692,    4, 3870,\n",
            "           27,   43,   69, 1495,   19, 2382, 1348,   72, 4576,  241,   80,  101,\n",
            "          108, 3754,    2,   52,  162,   14,   69],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,  795,    2, 2114,  103,\n",
            "          320,  166,  142,    3, 2033,    5,    2],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,   25,    5,   75,  538, 1702,  456,    2,\n",
            "           48,   37,    3,   44,   43,   18,   29],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,  795,    3,   46,   37, 1969,   11,\n",
            "            3,  656, 4828,  110, 1681,  416,   11],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,  156,  110,   21,\n",
            "          898,  107, 4016,   33,   27,   64,   36],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,  901,   23,   12, 1360,  167,   41,   53,    7,\n",
            "          263,   40,   47,  925,   41, 4590,    7],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    3,  296,   18,   14,\n",
            "         7487,  602,   12,   62,  198,  396,    2],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    9,\n",
            "          470, 1950,  127,   37,  115, 6890,    2],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,   84,\n",
            "            8, 1731,    4, 6925,    9,  532,    2,   18,   49, 1339,    5,  209,\n",
            "         1762, 1068,    4,  532,   20, 6613,    2],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,  346,   17,  632,   75,\n",
            "         6465,    6,    5,  117, 7101,   60,    7],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,  427,  126,  184,   16, 2062],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1, 2926,\n",
            "           21,   57,   14,   20,  805,  853,    7],\n",
            "        [   1,    1,    1,   23,    5,  519, 1383,   24,   56,    5,  186,  546,\n",
            "            6,  685,  104, 6955,  321,    5,   14,  140, 2879,   13,  733,  546,\n",
            "         1992,  321,    5,   14,    8, 5934,    7],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,  275,   18,  442,   16,\n",
            "          315,   11,  259,  266,    4, 2602, 1373,   31, 2042,   11,   14,  110,\n",
            "         2135, 3933, 5103,    4,  139,  111,    7],\n",
            "        [   1,    1,    1,    1,  279,   10,  124,   26, 3636,    2,   20, 2465,\n",
            "          834,   62,   55, 3288,  303,   41, 1463,  182,  600,  517,  585,  531,\n",
            "          373, 3826, 6431, 3755,  359,  301,  191],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,  160,\n",
            "           86,   12,  338,   47, 1361,  106,    7],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,  135,   30,    5,  666,    7],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,  112,  477,  176,   18,    4,  745,   22, 2152,    2,   83,\n",
            "         5467,   13, 1372, 2152,   30, 1404,    2],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,   17,  844,   58,  482,   74,   37,  515,    4,   25,  853,    2,\n",
            "           23,    5,   92,  853,   89,   80,    7]], device='cuda:0') shape torch.Size([32, 31])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 1628,  304,    2],\n",
            "        [   1,    1,    1,  ..., 2065,   13, 5688],\n",
            "        [   1,    1,    1,  ...,    5,  186,  245],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   17, 1322,   21],\n",
            "        [   1,    1,    1,  ..., 1070,  264,    2],\n",
            "        [   1,    1,    1,  ...,  226,   42,   66]], device='cuda:0') shape torch.Size([32, 69])\n",
            "targets: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,  636,   69,  ...,  243,  282,  191],\n",
            "        [   1,    1,    1,  ...,   60,  118,   57],\n",
            "        [   1,    1,    1,  ...,  204,  545,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  257,  258,    7],\n",
            "        [   1,    1,    1,  ...,   24,   63,    7],\n",
            "        [   1,    1,    1,  ...,  213, 1969,   11]], device='cuda:0') shape torch.Size([32, 37])\n",
            "targets: tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  282, 7108, 7705],\n",
            "        [   1,    1,    1,  ...,  145,  125,    2],\n",
            "        [   1,    1,    1,  ...,   60,  123,  130],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  372, 1581,    2],\n",
            "        [   1,    1,    1,  ...,    4,  833,    2],\n",
            "        [   1,    1,    1,  ...,  123,  467, 5162]], device='cuda:0') shape torch.Size([32, 37])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   3,   46,  277,  ...,   50, 5641,    2],\n",
            "        [   1,    1,    1,  ...,   15, 6392,    7],\n",
            "        [   1,    1,    1,  ...,   20,   86,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   13,  614,  231],\n",
            "        [   1,    1,    1,  ...,  718, 7125,   11],\n",
            "        [   1,    1,    1,  ...,   38, 1983,    7]], device='cuda:0') shape torch.Size([32, 48])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   18,   34, 6824],\n",
            "        [   1,    1,    1,  ...,   26,   16,  343],\n",
            "        [   1,    1,    1,  ...,   95,  890,  311],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  587,  426,    7],\n",
            "        [   1,    1,    1,  ...,  199,  483,    2],\n",
            "        [   1,    1,    1,  ...,    6,  783,    2]], device='cuda:0') shape torch.Size([32, 35])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   33,  489,    7],\n",
            "        [   1,    1,    1,  ...,   24,   34, 1213],\n",
            "        [   1,    1,    1,  ..., 6195,  455,   27],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  152,  471,   11],\n",
            "        [   1,    1,    1,  ...,  188,  333,   10],\n",
            "        [   1,    1,    1,  ...,    4,  289,  883]], device='cuda:0') shape torch.Size([32, 69])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    8, 6649,    2],\n",
            "        [ 634,   47, 1186,  ...,   80,  110,    2],\n",
            "        [   1,    1,    1,  ...,   34,  220,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1590,   52,   86],\n",
            "        [   1,    1,    1,  ...,   42, 2858,  367],\n",
            "        [   1,    1,    1,  ...,   48,    3, 1349]], device='cuda:0') shape torch.Size([32, 41])\n",
            "targets: tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[ 146,    3,  205,  ...,   36,  415,    7],\n",
            "        [   1,    1,    1,  ..., 1820,   76,  388],\n",
            "        [   1,    1,    1,  ...,    3,  383,   78],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   13, 6622,   10],\n",
            "        [   1,    1,    1,  ..., 5446,  110,   21],\n",
            "        [   1,    1,    1,  ...,   90,    8,  170]], device='cuda:0') shape torch.Size([32, 54])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[  1,   1,   1,  ...,  78, 991,   7],\n",
            "        [  1,   1,   1,  ...,   5, 758,  73],\n",
            "        [  1,   1,   1,  ...,  43, 102,   2],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ..., 330,  20, 138],\n",
            "        [  1,   1,   1,  ..., 906,   5,   7],\n",
            "        [  1,   1,   1,  ...,   4, 108, 883]], device='cuda:0') shape torch.Size([32, 41])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[  1,   1,   1,  ...,  40,  97, 271],\n",
            "        [  1,   1,   1,  ...,  15, 346, 672],\n",
            "        [  1,   1,   1,  ...,  71,  52,   2],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,  41, 198,   2],\n",
            "        [  1,   1,   1,  ...,  64,  36,   2],\n",
            "        [  1,   1,   1,  ...,  78,   5, 144]], device='cuda:0') shape torch.Size([32, 40])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 1456, 3400,    2],\n",
            "        [   1,    1,    1,  ..., 2406,  735, 2327],\n",
            "        [   1,    1,    1,  ...,   14,  102,  271],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    4,  166,   11],\n",
            "        [   1,    1,    1,  ..., 4412,    2,  219],\n",
            "        [   1,    1,    1,  ...,  475,  545,    2]], device='cuda:0') shape torch.Size([32, 50])\n",
            "targets: tensor([0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   41,  120,   29],\n",
            "        [   1,    1,    1,  ...,  721,  534,    7],\n",
            "        [   1,    1,    1,  ..., 3001,   41, 7173],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   10,   10,   10],\n",
            "        [   1,    1,    1,  ...,  167,   21, 1487],\n",
            "        [   1,    1,    1,  ..., 1521,  214,    7]], device='cuda:0') shape torch.Size([32, 76])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[ 122,   53,  640,  ..., 1046,  128,    2],\n",
            "        [   1,    1,    1,  ...,   19, 6382, 6692],\n",
            "        [  56,   14,  420,  ...,   30,  396,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    2,  393,  513],\n",
            "        [   1,    1,    1,  ...,   85,   16,  595],\n",
            "        [   1,    1,    1,  ...,  282,  191, 7782]], device='cuda:0') shape torch.Size([32, 39])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  121,    5,  164],\n",
            "        [   1,    1,    1,  ...,  319,   68,    2],\n",
            "        [   1,    1,    1,  ...,   19,  204,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   43,   68,    2],\n",
            "        [   1,    1,    1,  ..., 3921,    2, 7408],\n",
            "        [   1,    1,    1,  ...,   96, 5046,    7]], device='cuda:0') shape torch.Size([32, 39])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   22, 1033,   11],\n",
            "        [   1,    1,    1,  ..., 1737,   42, 3395],\n",
            "        [   1,    1,    1,  ..., 5635,   14, 1018],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1603,   10,   73],\n",
            "        [   1,    1,    1,  ...,  114,   18,   11],\n",
            "        [   1,    1,    1,  ...,  111,   29,    7]], device='cuda:0') shape torch.Size([32, 55])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 7502, 4996,    2],\n",
            "        [   1,    1,    1,  ..., 1240,  607,  231],\n",
            "        [   1,    1,    1,  ...,   37, 1406,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  152, 3144,   21],\n",
            "        [   1,    1,    1,  ...,   41, 1639,    2],\n",
            "        [   1,    1,    1,  ...,   52,  125,    7]], device='cuda:0') shape torch.Size([32, 37])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   13, 2277,    7],\n",
            "        [   1,    1,    1,  ...,    2, 6220,   66],\n",
            "        [   1,    1,    1,  ...,   10, 4400,  191],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1747,  570,   21],\n",
            "        [   1,    1,    1,  ...,    4,   40,  123],\n",
            "        [   1,    1,    1,  ...,    5,  273,    2]], device='cuda:0') shape torch.Size([32, 95])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   36,   42,  195],\n",
            "        [   1,    1,    1,  ..., 2740,   66,    2],\n",
            "        [   1,    1,    1,  ...,    9,  116,  155],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  539, 5063,    2],\n",
            "        [   1,    1,    1,  ...,    1,   63,    2],\n",
            "        [   1,    1,    1,  ...,  383,   95,   21]], device='cuda:0') shape torch.Size([32, 48])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   26, 3558,    2],\n",
            "        [   1,    1,    1,  ...,    1,   63,   11],\n",
            "        [   1,    1,    1,  ...,  278,   57,  736],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   68,   19,   16],\n",
            "        [   1,    1,    1,  ...,  301,  669, 3460],\n",
            "        [   1,    1,    1,  ...,  186,  277,    7]], device='cuda:0') shape torch.Size([32, 34])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   16,  157,   11],\n",
            "        [   1,    1,    1,  ...,  181, 4856, 5072],\n",
            "        [   1,    1,    1,  ..., 3484,  494,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1289,   29,    7],\n",
            "        [   1,    1,    1,  ...,  145,  304,   10],\n",
            "        [   1,    1,    1,  ..., 4579,  832,   10]], device='cuda:0') shape torch.Size([32, 68])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   15, 2620, 2603],\n",
            "        [   1,    1,    1,  ...,  713,   93,  108],\n",
            "        [   1,    1,    1,  ...,   15,  486, 2063],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 3097,  501,    2],\n",
            "        [   1,    1,    1,  ...,    6,  326,    2],\n",
            "        [   1,    1,    1,  ..., 1991,  582,    7]], device='cuda:0') shape torch.Size([32, 102])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  727,   76, 4805],\n",
            "        [   1,    1,    1,  ...,    4,  185,    5],\n",
            "        [   1,    1,    1,  ...,   28,    4, 2125],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   50,   16,  231],\n",
            "        [   1,    1,    1,  ...,   68, 1475,    7],\n",
            "        [   1,    1,    1,  ...,    4,  334,   70]], device='cuda:0') shape torch.Size([32, 41])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  120,  289, 2921],\n",
            "        [   1,    1,    1,  ...,   15,  474,   21],\n",
            "        [   1,    1,    1,  ...,  188,   29,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  164,  920,    7],\n",
            "        [   1,    1,    1,  ...,  172,  220,   21],\n",
            "        [   1,    1,    1,  ...,  889,   45,  405]], device='cuda:0') shape torch.Size([32, 55])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   3,   70,    5,  ...,   44, 1002,  108],\n",
            "        [   1,    1,    1,  ...,  986,   21,  164],\n",
            "        [   1,    1,    1,  ...,   87,   45,  405],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  248, 2118,    2],\n",
            "        [   1,    1,    1,  ...,   20,  116,  291],\n",
            "        [   1,    1,    1,  ...,  254, 3935,   66]], device='cuda:0') shape torch.Size([32, 68])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 3033, 1210,   83],\n",
            "        [   1,    1,    1,  ...,    9,  291,    2],\n",
            "        [   1,    1,    1,  ...,   58,  504,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  685,    7,  682],\n",
            "        [   1,    1,    1,  ..., 2567, 2992, 2421],\n",
            "        [   1,    1,    1,  ..., 4418,   60,   78]], device='cuda:0') shape torch.Size([32, 46])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   43,  126,  264],\n",
            "        [   1,    1,    1,  ..., 2166,   97, 3377],\n",
            "        [   1,    1,    1,  ...,   81,  238, 6849],\n",
            "        ...,\n",
            "        [  77,  116,   32,  ...,   76, 6002, 5837],\n",
            "        [   1,    1,    1,  ...,   32, 1630,    7],\n",
            "        [   1,    1,    1,  ...,   30,   68,  157]], device='cuda:0') shape torch.Size([32, 33])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  347,  155,    7],\n",
            "        [   1,    1,    1,  ..., 4394,  674,  523],\n",
            "        [   1,    1,    1,  ...,  708,  456,  157],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1382, 1401,    2],\n",
            "        [   1,    1,    1,  ...,   96,   12,    7],\n",
            "        [   1,    1,    1,  ...,  550,  356,   21]], device='cuda:0') shape torch.Size([32, 33])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   47,  711,  437],\n",
            "        [   1,    1,    1,  ...,   16, 1285,    7],\n",
            "        [   1,    1,    1,  ...,   80,    2, 6036],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  241,  138,  231],\n",
            "        [   1,    1,    1,  ...,   58, 1412,    2],\n",
            "        [  45,   70, 7227,  ..., 3494,  145, 5377]], device='cuda:0') shape torch.Size([32, 74])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   17,  172,  178],\n",
            "        [   1,    1,    1,  ...,  254, 6140,   66],\n",
            "        [   1,    1,    1,  ...,   15,    8,  654],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 4121,  160,   11],\n",
            "        [   1,    1,    1,  ...,  466,   42,   66],\n",
            "        [   1,    1,    1,  ..., 1535,  938,   10]], device='cuda:0') shape torch.Size([32, 102])\n",
            "targets: tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  273,  214,    2],\n",
            "        [   1,    1,    1,  ..., 1128,   21,   73],\n",
            "        [   1,    1,    1,  ...,  169,   26,  151],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 4287, 6347,   66],\n",
            "        [   1,    1,    1,  ...,  235,  592,    2],\n",
            "        [   1,    1,    1,  ...,    5,   15, 3391]], device='cuda:0') shape torch.Size([32, 43])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   64,   36,    7],\n",
            "        [   1,    1,    1,  ...,  246,    4,  681],\n",
            "        [   1,    1,    1,  ...,  455,   42,   66],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    8, 7663, 4042],\n",
            "        [   1,    1,    1,  ...,   47,  635,    2],\n",
            "        [   1,    1,    1,  ...,    4,   84,  305]], device='cuda:0') shape torch.Size([32, 51])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   13, 1882,    2],\n",
            "        [   1,    1,    1,  ..., 2385,    6, 7277],\n",
            "        [   1,    1,    1,  ...,  138,  148,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    2,   21,   73],\n",
            "        [   1,    1,    1,  ...,  971,  488,    2],\n",
            "        [   1,    1,    1,  ...,    4, 2776,   21]], device='cuda:0') shape torch.Size([32, 43])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    4,  284,    2],\n",
            "        [   1,    1,    1,  ...,   22,  167,    7],\n",
            "        [   1,    1,    1,  ...,   83,   38, 1118],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   20,   80,    2],\n",
            "        [   1,    1,    1,  ..., 2007,  534,    7],\n",
            "        [   1,    1,    1,  ...,  553,  304,    2]], device='cuda:0') shape torch.Size([32, 48])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  352,   29,    7],\n",
            "        [   1,    1,    1,  ..., 3005,    2, 1269],\n",
            "        [   1,    1,    1,  ...,   10,   42, 3497],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   44,   81,  178],\n",
            "        [   1,    1,    1,  ...,  435, 2424,    7],\n",
            "        [   1,    1,    1,  ...,   12,  307,    7]], device='cuda:0') shape torch.Size([32, 91])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  230,   76, 3050],\n",
            "        [   1,    1,    1,  ...,    4,  185,   60],\n",
            "        [   1,    1,    1,  ...,   40,  215,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  116, 5288,   29],\n",
            "        [   1,    1,    1,  ..., 5284,   42,   66],\n",
            "        [   1,    1,    1,  ...,  153,    4, 4475]], device='cuda:0') shape torch.Size([32, 67])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   81,   72,   11],\n",
            "        [   1,    1,    1,  ...,  137,   13, 1385],\n",
            "        [   1,    1,    1,  ...,   38, 6219,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   43,    9, 1013],\n",
            "        [   1,    1,    1,  ..., 1077,   22,  125],\n",
            "        [   1,    1,    1,  ...,  281, 2196,   10]], device='cuda:0') shape torch.Size([32, 46])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[7055,   10,   10,  ..., 2041,   12,   42],\n",
            "        [   1,    1,    1,  ...,    5,  477, 1230],\n",
            "        [   1,    1,    1,  ...,  131,   96,   18],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  329,  178,   72],\n",
            "        [   1,    1,    1,  ...,  612,  555,   11],\n",
            "        [   1,    1,    1,  ...,    8, 3202,   80]], device='cuda:0') shape torch.Size([32, 46])\n",
            "targets: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   40, 1665, 1298],\n",
            "        [   1,    1,    1,  ..., 2294, 6901,   11],\n",
            "        [   1,    1,    1,  ...,   73,  231,   73],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   30,   45,  666],\n",
            "        [   1,    1,    1,  ...,  108, 2813, 3081],\n",
            "        [   1,    1,    1,  ...,  125,    7,    7]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    1,   63,   11],\n",
            "        [   1,    1,    1,  ...,  301,  191,  595],\n",
            "        [   1,    1,    1,  ...,  108, 2813, 3081],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 6026, 3787,    2],\n",
            "        [   1,    1,    1,  ...,  395,   61,    5],\n",
            "        [   1,    1,    1,  ...,   14,  573,   21]], device='cuda:0') shape torch.Size([32, 92])\n",
            "targets: tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   41, 4480,   27],\n",
            "        [   1,    1,    1,  ..., 2198, 4547,   66],\n",
            "        [   1,    1,    1,  ...,   95,  271,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   44,   26,    5],\n",
            "        [   1,    1,    1,  ...,   12,   32,    2],\n",
            "        [   1,    1,    1,  ...,  151,  443, 3315]], device='cuda:0') shape torch.Size([32, 39])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  252,  623, 3587],\n",
            "        [   1,    1,    1,  ...,  880, 7485,  147],\n",
            "        [   1,    1,    1,  ..., 3448,   60,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   25,   53,    2],\n",
            "        [   1,    1,    1,  ...,   17,  454,   73],\n",
            "        [   1,    1,    1,  ...,   40,   78,   38]], device='cuda:0') shape torch.Size([32, 48])\n",
            "targets: tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    4,  249,    2],\n",
            "        [   1,    1,    1,  ...,  186,  277,   11],\n",
            "        [   1,    1,    1,  ...,   11,  698,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1104,   13,  546],\n",
            "        [   1,    1,    1,  ...,   76, 2287,  282],\n",
            "        [   1,    1,    1,  ...,   15, 1128,   73]], device='cuda:0') shape torch.Size([32, 65])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  313,  699,    2],\n",
            "        [   1,    1,    1,  ...,   10,   10,   10],\n",
            "        [   1,    1,    1,  ...,  177,  244,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   22,  106,   10],\n",
            "        [   1,    1,    1,  ...,  173,  148,   73],\n",
            "        [   1,    1,  609,  ..., 1260, 1741,  282]], device='cuda:0') shape torch.Size([32, 36])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 1667,   76,  243],\n",
            "        [   1,    1,    1,  ...,  379,  121,    5],\n",
            "        [   1,    1,    1,  ...,  346,  691,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  401,    2,  105],\n",
            "        [   1,    1,    1,  ...,   19, 5959,    2],\n",
            "        [   1,    1,    1,  ...,  203,   16,    7]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   19,    9, 2064],\n",
            "        [   1,    1,    1,  ...,  240,   80,  829],\n",
            "        [ 154,  200,    6,  ...,    4,   23,  200],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1541,   76, 5426],\n",
            "        [   1,    1,    1,  ...,   40,   12,   10],\n",
            "        [   1,    1,    1,  ...,  466,  234,  222]], device='cuda:0') shape torch.Size([32, 82])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 1, 0, 0, 1, 1, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 1310, 1805,    2],\n",
            "        [   1,    1,    1,  ..., 2343, 3045, 2389],\n",
            "        [   1,    1,    1,  ...,  147,  149,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1237,   42,   66],\n",
            "        [   1,    1,    1,  ...,  414,  138,  293],\n",
            "        [   1,    1,    1,  ...,   61, 5476,    2]], device='cuda:0') shape torch.Size([32, 36])\n",
            "targets: tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    6,  521,    7],\n",
            "        [   1,    1,    1,  ...,   34,    9, 3127],\n",
            "        [   1,    1,   20,  ...,  504,   26,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  244,   72,    2],\n",
            "        [   1,    1,    1,  ...,   46,   69,   11],\n",
            "        [   1,    1,    1,  ...,   79,  791,   10]], device='cuda:0') shape torch.Size([32, 36])\n",
            "targets: tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  790, 5558,    2],\n",
            "        [   1,    1,    1,  ...,   20,  220,    7],\n",
            "        [   1,    1,    1,  ..., 2203,    2, 6644],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 5419, 4477,    2],\n",
            "        [   1,    1,    1,  ...,   16,   70,    2],\n",
            "        [   1,    1,    1,  ..., 1737,   42, 3395]], device='cuda:0') shape torch.Size([32, 43])\n",
            "targets: tensor([1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  763,    4, 2425],\n",
            "        [   1,    1,    1,  ...,  257, 6334,  933],\n",
            "        [   1,    1,    1,  ...,   50,  222,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 4980,   41, 4127],\n",
            "        [   1,    1,    1,  ...,   17,  925,   21],\n",
            "        [   1,    1,    1,  ...,   67,    9,  309]], device='cuda:0') shape torch.Size([32, 40])\n",
            "targets: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    9, 1046,    7],\n",
            "        [   1,    1,    1,  ...,    4,  578,   11],\n",
            "        [   1,    1,    1,  ..., 7402,   42,   66],\n",
            "        ...,\n",
            "        [  54,    2,    3,  ..., 6160,  734,    2],\n",
            "        [   1,    1,    1,  ...,  890,  302,  211],\n",
            "        [   1,    1,    1,  ...,  218, 4387,    7]], device='cuda:0') shape torch.Size([32, 61])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  107,   12,    7],\n",
            "        [   1,    1,    1,  ...,   41,  827,    2],\n",
            "        [   1,    1,    1,  ...,    8, 1041,    5],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   47,  291,    7],\n",
            "        [   1,    1,    1,  ...,   74,  461,    2],\n",
            "        [  52,   14,  977,  ...,    2,  105,    2]], device='cuda:0') shape torch.Size([32, 54])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    6, 4706,   21],\n",
            "        [   1,    1,    1,  ...,   50,    8, 1096],\n",
            "        [   1,    1,    1,  ...,    5,  186,  141],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  113,  113,  113],\n",
            "        [   1,    1,    1,  ..., 3418,   21, 2811],\n",
            "        [   1,    1,    1,  ...,  204,  315,   11]], device='cuda:0') shape torch.Size([32, 40])\n",
            "targets: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
            "        0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,  809,    4,   16],\n",
            "        [   1,    1,    1,  ...,  434,  310,   11],\n",
            "        [   1,    1,    1,  ...,   41,   26,  895],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   47, 2807,    7],\n",
            "        [   1,    1,    1,  ..., 1025,    4, 1481],\n",
            "        [   1,    1,    1,  ...,  171, 2610,    2]], device='cuda:0') shape torch.Size([32, 39])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    8,  342,    2],\n",
            "        [   1,    1,    1,  ..., 3680, 5518, 6245],\n",
            "        [   1,    1,    1,  ...,   76, 1630, 5988],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   38,   95,   11],\n",
            "        [   1,    1,    1,  ...,   43, 1677, 1490],\n",
            "        [   1,    1,    1,  ...,   50,   16,   21]], device='cuda:0') shape torch.Size([32, 116])\n",
            "targets: tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   20, 4178,    7],\n",
            "        [   1,    1,    1,  ...,   69,   28, 2333],\n",
            "        [   1,    1,    1,  ...,   31, 1769,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   16,  688,   11],\n",
            "        [   1,    1,    1,  ...,   18,   42,   66],\n",
            "        [   1,    1,    1,  ...,    5, 6378,    7]], device='cuda:0') shape torch.Size([32, 157])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    5,  148,   21],\n",
            "        [   1,    1,    1,  ...,  298, 1041,   11],\n",
            "        [   1,    1,    1,  ...,  286,   26,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  963,   94,   21],\n",
            "        [   1,    1,    1,  ...,  465,  659,   11],\n",
            "        [   1,    1,    1,  ...,   21,   42,   66]], device='cuda:0') shape torch.Size([32, 196])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[  1,   1,   1,  ...,   3,  74, 709],\n",
            "        [  1,   1,   1,  ...,  10, 789,  12],\n",
            "        [  1,   1,   1,  ..., 404, 128,   2],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   4, 530,   7],\n",
            "        [  1,   1,   1,  ...,   6,  26,  16],\n",
            "        [  1,   1,   1,  ...,  41,  54,   2]], device='cuda:0') shape torch.Size([32, 42])\n",
            "targets: tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 6705,    4,  606],\n",
            "        [   1,    1,    1,  ..., 3401,   54,   21],\n",
            "        [   1,    1,    1,  ..., 5440,    8, 5442],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    9,  153,    2],\n",
            "        [   1,    1,    1,  ...,  230,   76, 3051],\n",
            "        [   1,    1,    1,  ...,   17,  291,    2]], device='cuda:0') shape torch.Size([32, 50])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ..., 2954,   73,   35],\n",
            "        [   1,    1,    1,  ...,  140, 5471,    7],\n",
            "        [   1,    1,    1,  ...,    9,  866, 6821],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  632, 6994,   72],\n",
            "        [   1,    1,    1,  ...,   24,   67,    7],\n",
            "        [   1,    1,    1,  ...,   87,  126,    7]], device='cuda:0') shape torch.Size([32, 38])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
            "        0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   46,  957,   11],\n",
            "        [   1,    1,    1,  ..., 2406,  735, 2327],\n",
            "        [   1,    1,    1,  ..., 1948, 1679,   21],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  249,   15,   11],\n",
            "        [   1,    1,    1,  ...,  470,  838,    2],\n",
            "        [   1,    1,    1,  ...,  361,  315,   11]], device='cuda:0') shape torch.Size([32, 49])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,   12,   26,    2],\n",
            "        [   1,    1,    1,  ...,   22, 7646,    2],\n",
            "        [   1,    1,    1,  ...,  277,   24,   10],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  113,  113,  113],\n",
            "        [   1,    1,    1,  ...,   41,  160,    7],\n",
            "        [  79,  494,  343,  ...,   61,  931,    2]], device='cuda:0') shape torch.Size([32, 47])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([32])\n",
            "inputs: tensor([[   1,    1,    1,  ...,    9, 5328,    7],\n",
            "        [   1,    1,    1,  ...,   15,    8,  654],\n",
            "        [   1,    1,    1,  ...,  206,  283,   21],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   90,   18,  223],\n",
            "        [   1,    1,    1,  ...,  119,  501,    2],\n",
            "        [   1,    1,    1,  ...,  586,   14,   10]], device='cuda:0') shape torch.Size([28, 39])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0') shape torch.Size([28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q22DKf9Bz15E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e59a6b65-06e8-4dfb-f018-eaf7b952cef9"
      },
      "source": [
        "for inputs, targets in test_iter:\n",
        "  print(\"inputs:\", inputs, \"shape\", inputs.shape)\n",
        "  print(\"targets:\", targets, \"shape\", targets.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[ 25,   5, 739,  ..., 326,   7, 231],\n",
            "        [ 65,  30,  20,  ..., 483, 800,   7],\n",
            "        [343,   6, 272,  ...,  20, 616,   2],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1, 619],\n",
            "        [  1,   1,   1,  ...,   1,   1,  63],\n",
            "        [  1,   1,   1,  ...,   1,   1, 619]], device='cuda:0') shape torch.Size([256, 7])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([256])\n",
            "inputs: tensor([[  87, 1251,   12,  ...,  562,  963,    2],\n",
            "        [ 785, 1073,    0,  ...,   65,   96, 2386],\n",
            "        [ 180,   24,  540,  ...,  309,  909,    0],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   74,  172,  106],\n",
            "        [   1,    1,    1,  ...,    0,   79,    7],\n",
            "        [   1,    1,    1,  ...,  302,  438,    2]], device='cuda:0') shape torch.Size([256, 10])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape torch.Size([256])\n",
            "inputs: tensor([[  78,  186,  136,  ..., 3328,   97,    0],\n",
            "        [2565,   89,  505,  ...,  152,  508,  777],\n",
            "        [  79,  173,   17,  ..., 3316,   80,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    3,   46,  102],\n",
            "        [   1,    1,    1,  ...,   50,    5, 2214],\n",
            "        [   1,    1,    1,  ...,   10,    0, 2029]], device='cuda:0') shape torch.Size([256, 14])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0') shape torch.Size([256])\n",
            "inputs: tensor([[ 783,   11,   17,  ...,  205,  496,    2],\n",
            "        [   3,  540,  166,  ...,   38,  958,    0],\n",
            "        [ 308,    3,   46,  ...,    8, 2091,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   86,  591,   11],\n",
            "        [   1,    1,    1,  ...,    5,   70,    2],\n",
            "        [   1,    1,    1,  ...,    9,  474,    2]], device='cuda:0') shape torch.Size([256, 20])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0') shape torch.Size([256])\n",
            "inputs: tensor([[ 148, 2236,   47,  ...,  599,    4, 1482],\n",
            "        [  26, 5265,   19,  ..., 1010, 1495,   10],\n",
            "        [  17,  707,   14,  ...,  534,   94,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 1824,  311,    2],\n",
            "        [   1,    1,    1,  ...,   86,  747,    7],\n",
            "        [   1,    1,    1,  ...,  179,   24,    2]], device='cuda:0') shape torch.Size([256, 28])\n",
            "targets: tensor([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "        0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
            "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0') shape torch.Size([256])\n",
            "inputs: tensor([[ 314,    2,   54,  ...,   96,  199,    2],\n",
            "        [1355, 5927, 1405,  ...,   76,  211,   66],\n",
            "        [ 106,   34,  367,  ..., 3403,  120,  293],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   28,    0,    0],\n",
            "        [   1,    1,    1,  ...,   83,    2,    0],\n",
            "        [   1,    1,    1,  ..., 4140,  269,  130]], device='cuda:0') shape torch.Size([256, 36])\n",
            "targets: tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
            "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "        1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
            "        0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
            "        0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
            "        1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "        1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
            "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
            "        0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
            "        1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0], device='cuda:0') shape torch.Size([256])\n",
            "inputs: tensor([[   8,  462,  940,  ...,  254,  950,   73],\n",
            "        [   1,    1,    1,  ...,   12, 1219,   11],\n",
            "        [   1,    1,    1,  ...,  188, 1622,    2],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   20, 3165,    7],\n",
            "        [   1,    1,    1,  ...,    0,   90,    0],\n",
            "        [   1,    1,    1,  ...,  271,    2,  293]], device='cuda:0') shape torch.Size([136, 116])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
            "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0') shape torch.Size([136])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3zlUVkOz7lc"
      },
      "source": [
        "# AUTOREGRESSIVE RNN MODELS\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, n_vocab, embed_dim, n_hidden, n_rnnlayers,n_outputs):\n",
        "    super(RNN,self).__init__()\n",
        "    self.V = n_vocab\n",
        "    self.D = embed_dim\n",
        "    self.M = n_hidden\n",
        "    self.L = n_rnnlayers\n",
        "    self.K = n_outputs\n",
        "\n",
        "    # embedding layer \n",
        "    self.embed = nn.Embedding(self.V, self.D)\n",
        "    # lstm\n",
        "    self.rnn = nn.LSTM(input_size=self.D, hidden_size=self.M, num_layers=self.L, batch_first=True)\n",
        "    # final dense layer\n",
        "    self.fc = nn.Linear(self.M, self.K)\n",
        "\n",
        "  def forward(self,X):\n",
        "    # initial lstm states\n",
        "    h0 = torch.zeros(self.L, X.size(0),self.M).to(device)\n",
        "    c0 = torch.zeros(self.L, X.size(0),self.M).to(device)\n",
        "\n",
        "    # EMBEDDING LAYER - from N * T to N * T * D \n",
        "    out = self.embed(X)\n",
        "\n",
        "    # LSTM LAYER - out N * T * M\n",
        "    out, _ = self.rnn(out,(h0,c0))\n",
        "\n",
        "    # MAX POOL - OUT N * M\n",
        "    out, _ = torch.max(out,1)\n",
        "\n",
        "    # only h(t) at the final time step ---- N * K\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uPsl9Gb3Zrg"
      },
      "source": [
        "# run the RNN function\n",
        "model = RNN(len(vocab), 20, 15, 1, 1)\n",
        "# Move to GPU\n",
        "model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer used for the pytorch model\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anLoChvc6PVX"
      },
      "source": [
        "# A function to encapsulate the training loop\n",
        "def batch_gd(model, criterion, optimizer, train_iter, test_iter, epochs):\n",
        "  train_losses = np.zeros(epochs)\n",
        "  test_losses = np.zeros(epochs)\n",
        "\n",
        "  for it in range(epochs):\n",
        "    t0 = datetime.now()\n",
        "    train_loss = []\n",
        "    for inputs, targets in train_iter:\n",
        "      # move data to GPU\n",
        "      #inputs, targets = inputs.to(device), targets.to(device)\n",
        "      targets = targets.view(-1,1).float()\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "        \n",
        "      # Backward and optimize\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "    # Get train loss and test loss\n",
        "    train_loss = np.mean(train_loss) # a little misleading\n",
        "    \n",
        "    test_loss = []\n",
        "    for inputs, targets in test_iter:\n",
        "      #inputs, targets = inputs.to(device), targets.to(device)\n",
        "      targets = targets.view(-1,1).float()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      test_loss.append(loss.item())\n",
        "    test_loss = np.mean(test_loss)\n",
        "\n",
        "    # Save losses\n",
        "    train_losses[it] = train_loss\n",
        "    test_losses[it] = test_loss\n",
        "    \n",
        "    dt = datetime.now() - t0\n",
        "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "      Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
        "  \n",
        "  return train_losses, test_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5EnNJFu62Vm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f718b2ed-009f-4a9f-8879-d002a8b6d018"
      },
      "source": [
        "# call the training function\n",
        "train_losses, test_losses = batch_gd(\n",
        "    model, criterion, optimizer, train_iter, test_iter, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Train Loss: 0.0114,       Test Loss: 0.2040, Duration: 0:00:01.428318\n",
            "Epoch 2/20, Train Loss: 0.0103,       Test Loss: 0.2083, Duration: 0:00:01.433373\n",
            "Epoch 3/20, Train Loss: 0.0103,       Test Loss: 0.1891, Duration: 0:00:01.416064\n",
            "Epoch 4/20, Train Loss: 0.0173,       Test Loss: 0.1609, Duration: 0:00:01.414988\n",
            "Epoch 5/20, Train Loss: 0.0093,       Test Loss: 0.1681, Duration: 0:00:01.429406\n",
            "Epoch 6/20, Train Loss: 0.0083,       Test Loss: 0.1727, Duration: 0:00:01.383512\n",
            "Epoch 7/20, Train Loss: 0.0075,       Test Loss: 0.1735, Duration: 0:00:01.389001\n",
            "Epoch 8/20, Train Loss: 0.0073,       Test Loss: 0.1765, Duration: 0:00:01.391216\n",
            "Epoch 9/20, Train Loss: 0.0064,       Test Loss: 0.1924, Duration: 0:00:01.396253\n",
            "Epoch 10/20, Train Loss: 0.0056,       Test Loss: 0.1956, Duration: 0:00:01.393510\n",
            "Epoch 11/20, Train Loss: 0.0051,       Test Loss: 0.1959, Duration: 0:00:01.418569\n",
            "Epoch 12/20, Train Loss: 0.0048,       Test Loss: 0.2011, Duration: 0:00:01.404619\n",
            "Epoch 13/20, Train Loss: 0.0044,       Test Loss: 0.2020, Duration: 0:00:01.388353\n",
            "Epoch 14/20, Train Loss: 0.0042,       Test Loss: 0.2070, Duration: 0:00:01.430262\n",
            "Epoch 15/20, Train Loss: 0.0040,       Test Loss: 0.2111, Duration: 0:00:01.424515\n",
            "Epoch 16/20, Train Loss: 0.0041,       Test Loss: 0.1891, Duration: 0:00:01.445953\n",
            "Epoch 17/20, Train Loss: 0.0038,       Test Loss: 0.1987, Duration: 0:00:01.416555\n",
            "Epoch 18/20, Train Loss: 0.0039,       Test Loss: 0.1969, Duration: 0:00:01.440272\n",
            "Epoch 19/20, Train Loss: 0.0028,       Test Loss: 0.2101, Duration: 0:00:01.399890\n",
            "Epoch 20/20, Train Loss: 0.0025,       Test Loss: 0.2063, Duration: 0:00:01.432573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA5cwJeI6_V2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5ba23bfe-b6dc-4649-cfbf-e9379af9ab78"
      },
      "source": [
        "# Plot the train loss and test loss per iteration\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REl5s6z47ETY"
      },
      "source": [
        "# accuracy for train and test data\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "\n",
        "for inputs, targets in train_iter:\n",
        "  targets = targets.view(-1,1).float()\n",
        "\n",
        "  # forwards pass\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  # predictions\n",
        "  predictions = outputs > 0\n",
        "\n",
        "  # update counts\n",
        "  n_correct += (predictions == targets).sum().item()\n",
        "  n_total += targets.shape[0]\n",
        "\n",
        "train_acc = n_correct/n_total\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "\n",
        "\n",
        "y_test = []\n",
        "p_test = []\n",
        "\n",
        "for inputs, targets in test_iter:\n",
        "  targets = targets.view(-1,1).float()\n",
        "\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  predictions = list((outputs > 0).cpu().numpy())\n",
        "\n",
        "  y_test += list(targets.cpu().numpy())\n",
        "  p_test += predictions\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA2vz8vI_f4B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f014897-4683-4b01-b72f-dd6a875f0faf"
      },
      "source": [
        "# train and test accuracy --- 94% test accuracy!\n",
        "print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.9997, Test acc: 0.9444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyuYxgq3_jiI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa89908a-3d38-4b9f-e7ab-8bea88fe047f"
      },
      "source": [
        "df[df[\"labels\"] == \"spam\"].size / df.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13406317300789664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw8pqmRTbRIr"
      },
      "source": [
        "# confusion matrix to visualise results\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting `normalize=True`.\n",
        "  \"\"\"\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHHKxcciblrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "195fe315-8543-47be-8bff-da525b3420a8"
      },
      "source": [
        "cm = confusion_matrix(y_test, p_test)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1329,   98],\n",
              "       [  10,  235]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrLYpzHibwiK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "2f689e5b-e23e-406b-a676-3e866d8701b5"
      },
      "source": [
        "plot_confusion_matrix(cm, [0,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1329   98]\n",
            " [  10  235]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft3gDvaykIWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "ab08a5f3-d346-472c-f870-352a28e7ca3d"
      },
      "source": [
        "df[df.labels==\"spam\"].sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>data</th>\n",
              "      <th>b_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2132</th>\n",
              "      <td>spam</td>\n",
              "      <td>Your B4U voucher w/c 27/03 is MARSMS. Log onto...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>spam</td>\n",
              "      <td>Romantic Paris. 2 nights, 2 flights from å£79 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>spam</td>\n",
              "      <td>+449071512431 URGENT! This is the 2nd attempt ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     labels                                               data  b_labels\n",
              "2132   spam  Your B4U voucher w/c 27/03 is MARSMS. Log onto...         1\n",
              "760    spam  Romantic Paris. 2 nights, 2 flights from å£79 ...         1\n",
              "716    spam  +449071512431 URGENT! This is the 2nd attempt ...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Qz1W9WmfP9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}